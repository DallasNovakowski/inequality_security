---
title: "01_security_pretest_clean"
author: "Dallas Novakowski"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(plyr)
library(tidyverse)
library(readxl)
library(here)

# raincloud plot
library(readr)
library(tidyr)
library(ggplot2)
library(Hmisc)
library(RColorBrewer)
library(reshape2)

#for raincloud plots
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")
```


```{r pilot data, eval = FALSE, warning=FALSE, echo=FALSE}
# out <- read_csv("C:/Users/dalla/Google Drive/offline_data_files/security_game/pilot_page_times_10_30.csv")
# 
# out2 <- read_csv("C:/Users/dalla/Google Drive/offline_data_files/security_game/pilot_page_times_11_01.csv")
# 
# out <- merge(out,out2, all = TRUE)

# read 
test_data <- read_csv("C:/Users/dalla/Google Drive/offline_data_files/security_game/security_pretest_all_apps_wide-2021-10-30.csv")

test_data2 <- read_csv("C:/Users/dalla/Google Drive/offline_data_files/security_game/security_pretest_all_apps_wide-2021-11-01.csv")

# page_times <- read_csv("C:/Users/dalla/Google Drive/offline_data_files/security_game/security_pretest_PageTimes-2021-11-12(1).csv")


test_data <- merge(test_data,test_data2, all = TRUE)

```


```{r import identified data, eval = FALSE, echo=FALSE}
# read timer data


page_times <-
  read_csv(
    "C:/Users/dalla/Google Drive/offline_data_files/security_game/security_pretest_processed_times-2021-11-12.csv"
  )

data <-
  read_csv(
    "C:/Users/dalla/Google Drive/offline_data_files/security_game/security_pretest_2021_11_21.csv"
  )


names(page_times) <-
  gsub(x = names(page_times),
       pattern = "\\._",
       replacement = "_")

names(page_times) <-
  gsub(x = names(page_times),
       pattern = "\\.",
       replacement = "_")

names(data) <-
  gsub(
    x = names(data),
    pattern = "._",
    replacement = "_",
    fixed = TRUE
  )
names(data) <-
  gsub(
    x = names(data),
    pattern = ".",
    replacement = "_",
    fixed = TRUE
  )

out_wide <-
  pivot_wider(
    page_times,
    id_cols = participant_code,
    names_from = page_name,
    names_prefix = "time_",
    values_from = seconds_on_page
  )

data <- data %>%
  left_join(out_wide, by = c("participant_code")) %>%
  select(-contains(c("prolific", "completion", "mturk"))) %>%
  filter(!is.na(participant_label))

# save identified data
save(data, file = "C:/Users/dalla/Google Drive/offline_data_files/security_game/ident_pretest_data.RData")

#de-identify
data <- data %>%
  select(-contains(c("participant_label")))

save(data, file = here::here("data", "pretest_data.RData"))
```


```{r name cleaning, warning=FALSE, echo=FALSE}
# here package being used because relative path is messing up (kicking me up to docs)
load(here::here("data", "pretest_data.RData"))


# delete columns totally unrelated to pretest
data <- data %>%
  select(-starts_with(
    c(
      "intro_notask",
      "slider_task",
      "merit",
      "security_game_1",
      "session"
    )
  )) %>%
  select(-contains(
    c(
      "payoff",
      "mturk",
      "id_in",
      "player_role",
      "bot",
      "_ts_",
      "index",
      "current",
      "time_started",
      "visited",
      "submit_missing",
      ".y",
      "round_number"
    )
  ))


# clean names
names(data) <-
  gsub(
    x = names(data),
    pattern = "questionnaires_1_player_",
    replacement = "",
    fixed = TRUE
  )
names(data) <-
  gsub(
    x = names(data),
    pattern = "intro_1_player_",
    replacement = "",
    fixed = TRUE
  )
names(data) <-
  gsub(
    x = names(data),
    pattern = "consent_1_player_",
    replacement = "",
    fixed = TRUE
  )
names(data) <-
  gsub(
    x = names(data),
    pattern = "session_config_",
    replacement = "",
    fixed = TRUE
  )


names(data) <-
  gsub(
    x = names(data),
    pattern = "attention_check_1_player_other",
    replacement = "attention_check_1_player_atn_other",
    fixed = TRUE
  )

names(data) <-
  gsub(
    x = names(data),
    pattern = "attention_check_1_player_",
    replacement = "",
    fixed = TRUE
  )

data <- data %>%
  select(-contains(
    c(
      "participation_fee",
      "real_world_currency_per_point",
      "attention_check_1_subsession_round_number",
      "completionlink",
      "oTree_version_used",
      "prolific_id"
    )
  ))

data$comments <-
  paste(data$comments, data$study_end_1_player_comments)

data <- subset(data, select = -study_end_1_player_comments)

names(data) <-
  gsub(
    x = names(data),
    pattern = ".x",
    replacement = "",
    fixed = TRUE
  )


data <- data %>%
  janitor::clean_names()      # clean names to be all lowercase, replacing spaces with "_"


names(data) <-
  gsub(
    x = names(data),
    pattern = "pre_test",
    replacement = "pretest",
    fixed = TRUE
  )
names(data) <-
  gsub(
    x = names(data),
    pattern = "security_game_pretest",
    replacement = "sg",
    fixed = TRUE
  )
names(data) <-
  gsub(
    x = names(data),
    pattern = "player_",
    replacement = "",
    fixed = TRUE
  )
names(data) <-
  gsub(
    x = names(data),
    pattern = "subsession_",
    replacement = "",
    fixed = TRUE
  )

pretest_initial_n <- nrow(data)
```


```{r filtering, echo=FALSE}
post_age_n  <- data %>%
  filter(!is.na(age)) %>%
  nrow()

#after first attention check
post_atn_n <- data %>%
  filter(atn_other == "yes" | atn_other == "Yes") %>%
  nrow()

#after second attention check
post_atn2_n <- data %>%
  filter(atn_other2 == "yes" | atn_other2 == "Yes") %>%
  nrow()

#filtering for people who moderately understood comprehension check
# data %>%
#   filter(comp_check == "Deciding whether to try stealing from me" | comp_check == "Deciding whether to purchase a security product") %>%
#   nrow()

# strict interpretation of comprehension check
post_comp_n <-  data %>%
  filter(comp_check == "Deciding whether to try stealing from me") %>%
  nrow()

```

```{r actual screening}
# actual screening, attention checks and moderate comprehension criteria
data <-  data %>%
  filter(!is.na(age) & !is.na(gender)) %>%
  filter(
    comp_check == "Deciding whether to try stealing from me" |
      comp_check == "Deciding whether to purchase a security product"
  ) %>%
  filter(atn_other2 == "yes" | atn_other2 == "Yes") %>%
  filter(atn_other == "yes" | atn_other == "Yes")

summary(as.factor(data$gender))
```


A substantial portion of the sample is lost during data quality screening. From an initial n =`r pretest_initial_n`, removing missing age responses yields n = `r post_age_n`, one attention check retains n =`r post_atn_n`, and (before attention check screening) a strict interpretation of the comprehension check yields n = `r post_comp_n`.

After all screening, and using a moderate threshold for comprehension checks, we are left with n=`r nrow(data)`

```{r aggregation, echo=FALSE}
# make lists of useful variables
time_vars <- colnames(data[grepl('time_', colnames(data))])
time_vars <-
  Filter(function(x)
    ! any(grepl("participant", x)), time_vars)
dospert_vars <- colnames(data[grepl('dospert_', colnames(data))])
iu_vars <- colnames(data[grepl('iu_', colnames(data))])
consumed_vars <-
  colnames(data[grepl('security_consumed', colnames(data))])
page_vars <- colnames(data[grepl('page_in_round', colnames(data))])

# make totals of variables
data$time_total <-
  rowSums(data[, time_vars], na.rm = TRUE) * NA ^ (rowSums(!is.na(data[, time_vars])) == 0)

data$iu_total <-
  rowSums(data[, iu_vars], na.rm = TRUE) * NA ^ (rowSums(!is.na(data[, iu_vars])) == 0)

data$dospert_total <-
  rowSums(data[, dospert_vars], na.rm = TRUE) * NA ^ (rowSums(!is.na(data[, dospert_vars])) == 0)

```


# Time spent on pages

How much time have participants spent on each task? Helps to tailor later studies.


```{r time}
time_data <- data[,time_vars] %>%
   na.omit()


boxplot(time_data)
```

We can see some outliers for time spent. At least for the purposes of estimating time spent, we should treat some outliers to prevent their outsized influence. By trimming them, we assume that these outliers are not "true" values, but rather reflect people drifting to another task.

```{r time filter}
time_data <- time_data %>%
  filter(time_consent <= 100 & time_dospert <= 550 & time_at_bo <= 20)

nrow(time_data)
```


```{r curate time}
time_means <- sapply(time_data, mean)

time_means


curate_time <-
  sum(time_means[c(
    "time_consent",
    "time_at_bo",
    "time_demographics",
    "time_task_intro",
    "time_pretest50_02",
    "time_iu",
    "time_iu",
    "time_ac1",
    "time_ac2",
    "time_cc",
    "time_comments",
    "time_consent"
  )])
```

After trimming some extreme observations, participants spent an average of `r round(sum(sapply(time_data, mean))/60,2)` minutes on the study. Our targeted configuration for our first inequality study, would take an estimated `r round(curate_time/60,2)` minutes.


```{r time detritus, eval=FALSE, warning=FALSE, echo=FALSE}

#time_pretest50_02 > 2 & time_pretest60_02 > 2 & time_pretest75_02 > 2 & time_pretest50_04 > 2 & time_pretest60_04 > 2 & time_pretest75_04 > 2


time_quantiles <- sapply(time_data, quantile)
```



# Consumption exploration

```{r pages in round, warning=FALSE, echo=FALSE}
data <- data %>%
  filter(!is.na(sg_2_security_consumed))

screened_n <- nrow(data)

```

After attention checks, we are left with `r nrow(data)` participants.

```{r within, warning=FALSE, echo=FALSE, message=FALSE, results='hide', include=FALSE}
# create long data for withing subjects analyses
data_long <- data %>% pivot_longer(consumed_vars, names_to = "round_num", values_to = "consumed")

# clean up round num variable
data_long$round_num <- data_long$round_num %>%
  sub("sg_", "", .) %>%
  sub("_security_consumed", "", .) %>%
  as.numeric()

# create variable to log page displayed page for each observation
data_long <- data_long %>%
  dplyr::mutate(page = ifelse(
    round_num == 1,
    sg_1_page_in_round,
    ifelse(
      round_num == 2,
      sg_2_page_in_round,
      ifelse(
        round_num == 3,
        sg_3_page_in_round,
        ifelse(
          round_num == 4,
          sg_4_page_in_round,
          ifelse(
            round_num == 5,
            sg_5_page_in_round,
            ifelse(round_num == 6, sg_6_page_in_round, NA)
          )
        )
      )
    )
  ))

# create variables for different levels of probability and cost
data_long <- data_long %>%
  dplyr::mutate(prob = ifelse(
    page == "PreTest50_02" | page == "PreTest50_04",
    50,
    ifelse(
      page == "PreTest60_02" | page == "PreTest60_04",
      60,
      ifelse(page == "PreTest75_02" |
               page == "PreTest75_04",  75, NA)
    )
  ))

data_long <- data_long %>%
  dplyr::mutate(
    cost = ifelse(
      page == "PreTest50_02" |
        page == "PreTest60_02" | page == "PreTest75_02",
      02,
      ifelse(
        page == "PreTest50_04" |
          page == "PreTest60_04" | page == "PreTest75_04",
        04,
        NA
      )
    )
  )


data_long$page <- data_long$page %>%
  sub("PreTest", "", .)

# create security consumption as proportion of whole
data_long <- data_long %>%
  mutate(prop_consumed = ifelse(cost == 4, consumed / 25,
                                ifelse(cost == 2, consumed / 50, NA)))

# create security spending variable
data_long <- data_long %>%
  mutate(security_spending = ifelse(cost == 4, consumed * .04,
                                    ifelse(cost == 2, consumed * .02, NA)))
```


```{r initial exploration, warning=FALSE, echo=FALSE}
# create utility items for later analyses and reporting
skew_groups <-
  by(data_long$security_spending, data_long$page, moments::skewness)

kurt_groups <-
  by(data_long$security_spending, data_long$page, moments::kurtosis)

sd_groups <- by(data_long$security_spending, data_long$page, sd)

mean_groups <- by(data_long$security_spending, data_long$page, mean)

base_mean <- mean_groups["50_02"]

base_sd <- sd_groups["50_02"]

base_skew <- skew_groups["50_02"]

overall_skew <- moments::skewness(data_long$security_spending)


# use this first time saving, resave every other time
# save(skew_groups, pretest_initial_n, screened_n, kurt_groups,sd_groups, mean_groups, base_skew,base_sd,base_mean, file = here::here("output", "pretest_output.RData"))


cgwtools::resave(
  skew_groups,
  pretest_initial_n,
  screened_n,
  kurt_groups,
  sd_groups,
  mean_groups,
  base_skew,
  base_sd,
  base_mean,
  overall_skew,
  file = here::here("output", "pretest_output.RData")
)


```

Note: for x_04 conditions, 25 constitutes the maximum possible value for consumption.

```{r page clean}



# increase legibility of page variable
data_long$page <- data_long$page %>%
  sub("_0", "%_", .)

data_long$page <- paste(data_long$page, "¢", sep = "", collapse = NULL)



```


```{r raincloud, warning=FALSE, echo=FALSE, message=FALSE}


raincloud_theme = theme(
  text = element_text(size = 10),
  axis.title.x = element_text(size = 16),
  axis.title.y = element_text(size = 16),
  axis.text = element_text(size = 14),
  axis.text.x = element_text(angle = 45, vjust = 0.5),
  legend.title = element_text(size = 16),
  legend.text = element_text(size = 16),
  legend.position = "right",
  plot.title = element_text(
    lineheight = .8,
    face = "bold",
    size = 16
  ),
  panel.border = element_blank(),
  panel.grid.minor = element_blank(),
  axis.line.x = element_line(
    colour = 'black',
    size = 0.5,
    linetype = 'solid'
  ),
  axis.line.y = element_line(
    colour = 'black',
    size = 0.5,
    linetype = 'solid'
  )
)


# stat_summary(fun = "mean",
#            geom = "crossbar",
#            width = 0.2,
#            colour = "grey",
#            position = position_nudge(x = .2, y = 0))


cbPalette <-
  c(
    "#999999",
    "#E69F00",
    "#56B4E9",
    "#009E73",
    "#F0E442",
    "#0072B2",
    "#D55E00",
    "#CC79A7"
  )


g <-
  ggplot(data = data_long, aes(y = consumed, x = page, fill = page)) +
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .8) +
  stat_summary(
    fun.data = "mean_cl_boot",
    geom = "pointrange",
    colour = "black",
    position = position_nudge(x = .27, y = 0),
    alpha = .5
  ) +
  
  ggbeeswarm::geom_quasirandom(aes(y = consumed, color = page),
                               ## draw bigger points
                               # size = 1,
                               ## add some transparency
                               alpha = .5,
                               ## control range of the beeswarm
                               width = .2)  +
  #
  # scale_color_brewer(palette = "Spectral") +
  # scale_fill_brewer(palette = "Spectral") +
  
  # geom_point(aes(y = consumed, color = page), position = position_jitter(width = .15), size = .5, alpha = 0.8) +
  geom_boxplot(
    width = .1,
    guides = FALSE,
    outlier.shape = NA,
    alpha = 0.5
  ) +
  expand_limits(x = 5.25) +
  guides(fill = FALSE) +
  guides(color = FALSE) +
  scale_fill_manual(values = cbPalette) +
  scale_colour_manual(values = cbPalette) +
  # coord_flip() +
  theme_bw() +
  raincloud_theme

g

ggsave(here::here("figures", "securitypretest_rainclouds.png"))
```


```{r splitdefine}
GeomSplitViolin <- ggproto(
  "GeomSplitViolin",
  GeomViolin,
  draw_group = function(self, data, ..., draw_quantiles = NULL) {
    data <- transform(
      data,
      xminv = x - violinwidth * (x - xmin),
      xmaxv = x + violinwidth * (xmax - x)
    )
    grp <- data[1, 'group']
    newdata <- plyr::arrange(transform(data, x = if (grp %% 2 == 1)
      xminv
      else
        xmaxv),
      if (grp %% 2 == 1)
        y
      else -y)
    newdata <-
      rbind(newdata[1,], newdata, newdata[nrow(newdata),], newdata[1,])
    newdata[c(1, nrow(newdata) - 1, nrow(newdata)), 'x'] <-
      round(newdata[1, 'x'])
    if (length(draw_quantiles) > 0 &
        !scales::zero_range(range(data$y))) {
      stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <= 1))
      quantiles <-
        ggplot2:::create_quantile_segment_frame(data, draw_quantiles)
      aesthetics <-
        data[rep(1, nrow(quantiles)), setdiff(names(data), c("x", "y")), drop = FALSE]
      aesthetics$alpha <- rep(1, nrow(quantiles))
      both <- cbind(quantiles, aesthetics)
      quantile_grob <- GeomPath$draw_panel(both, ...)
      ggplot2:::ggname("geom_split_violin",
                       grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
    } else {
      ggplot2:::ggname("geom_split_violin",
                       GeomPolygon$draw_panel(newdata, ...))
    }
  }
)

geom_split_violin <- function (mapping = NULL,
                               data = NULL,
                               stat = "ydensity",
                               position = "identity",
                               ...,
                               draw_quantiles = NULL,
                               trim = TRUE,
                               scale = "area",
                               na.rm = FALSE,
                               show.legend = NA,
                               inherit.aes = TRUE) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomSplitViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      draw_quantiles = draw_quantiles,
      na.rm = na.rm,
      ...
    )
  )
}
```


```{r spending}
# split violin - adapted from https://debruine.github.io/post/plot-comparison/

spending_summary_data <- data_long %>%
  group_by(prob, cost) %>%
  summarise(
    mean = mean(security_spending),
    min = mean(security_spending) - qnorm(0.975) * sd(security_spending) /
      sqrt(n()),
    max = mean(security_spending) + qnorm(0.975) * sd(security_spending) /
      sqrt(n())
  )


spending_pretest_splitplot <- data_long %>%
  ggplot(aes(
    y = security_spending,
    x = as.factor(prob),
    fill = as.factor(cost)
  )) +
  geom_split_violin(
    color = "black",
    trim = TRUE,
    alpha = 0.5,
    width = 1,
    # position = position_nudge(x = -.005)
  ) +
  geom_pointrange(
    data = spending_summary_data,
    aes(as.factor(prob), mean, ymin = min, ymax = max),
    color = "black",
    alpha = 0.5,
    shape = 20,
    # 95,
    position = position_dodge(width = 0.25),
    show.legend = FALSE
  ) +
  # geom_boxplot(color = "black",
  #            width = 0.1,
  #            alpha = .1,
  #            position = position_dodge(width=0.5)) +
  ylab("$ spent on security") +
  xlab("Starting probability of successful thefts") +
  labs(fill = "Security price (¢)") +
  ylim(0, 1) +
  scale_fill_manual(values = cbPalette) +
  scale_colour_manual(values = cbPalette) +
  scale_x_discrete(labels = c("50" = "50%", "60" = "60%",
                              "75" = "75%")) +
  theme_bw() +
  raincloud_theme

spending_pretest_splitplot

ggsave(here::here("figures", "spending_pretest_splitplot.png"),
       height = 3)

```

```{r, eval = F}
# data_long$spent2 <- paste0(data_long$security_spending, "2") # create a second almost identical variable
# 
# ggplot(data_long,aes(security_spending, value)) +
#   geom_beeswarm(aes(spent2),priority='random',cex=2.5) +
# 
# 
# spent_rain <- ggplot(data = data_long, aes(y = security_spending, x = as.factor(prob), fill = as.factor(cost))) +
#   geom_flat_violin(alpha = .8) +
#     geom_boxplot(width = .1, guides = FALSE, outlier.shape = NA, alpha = 0.5) +
#     geom_pointrange(
#     data = spending_summary_data,
#     aes(as.factor(prob), mean, ymin=min, ymax=max),
#     color = "black", 
#      alpha = 0.5,
#     shape = 20, # 95,
#     position = position_dodge(width = 0.25)) +
#   
#   
#   guides(fill = FALSE) +
#   guides(color = FALSE) +
#   scale_fill_manual(values=cbPalette)+
#   scale_colour_manual(values=cbPalette) +
# # coord_flip() +
#   theme_bw() +
#   raincloud_theme
# 
# 
# spent_rain

```

For this project, we will be using values from the 50_02 condition, which corresponds to a baseline 50% chance of successful thefts, and each unit of security costing $0.02. This condition seems to produce the least skewed data, at `r round(skew_groups["50_02"],2)`

```{r order analysis, warning=FALSE, echo=FALSE}
# models for analyzing order effects
m1_null <- lme4::lmer(security_spending ~  (1 | participant_code), data = data_long, REML=FALSE)

m1_order <- lmerTest::lmer(security_spending ~ as.numeric(round_num) + as.numeric(prob) + cost + (1 | participant_code), data = data_long, REML=TRUE)

pretest_model <- summary(m1_order)


pretest_model


cgwtools::resave(pretest_model, file = here::here("output", "pretest_output.RData"))
```

