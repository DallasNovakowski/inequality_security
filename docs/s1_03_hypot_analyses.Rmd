---
title: "s1_03_hypot_analyses"
author: "Dallas Novakowski"
date: "20/01/2022"
output: html_document
---

```{r hypot-setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)


library(tidyverse)
library(kableExtra)
library(lme4)
library(rstatix)  # t_test
library(stats)  #aov function
library(ggpubr)  #ggqqplot
library(afex) #aov_ez


library(mediation)
mediate <- mediation::mediate

library(emmeans)

source(here::here("scripts","hypotheses.R"), local = knitr::knit_global())
source(here::here("scripts","measures.R"), local = knitr::knit_global())
```

```{r testdata,echo=FALSE}
#used for 
set.seed(1234) #Standardizes the numbers generated by rnorm; see Chapter 5
N <- 200 #Number of participants; graduate students
inequality <- sample(c(0,1), replace=TRUE, size=N)
pnum <- seq_len(N)

stake_strings <- c("histak_loprob_loprice", "histak_loprob_hiprice", "histak_hiprob",
"lostak_loprob_loprice", "lostak_loprob_hiprice", "lostak_hiprob") 

# stake <- as.factor(sample(stake_strings, replace=TRUE, size=N))

# likely_envy <- round(1+1.5*inequality + rnorm(N, 0,2),2) #Suspected mediator 

# security_spending <- 2*likely_envy + rnorm(N, 0, 5) #DV

envy_lostak <- 2*likely_envy + rnorm(N, 0, 5)
envy_histak <- 2*likely_envy + rnorm(N, 0, 5)
ss_lostak <- 2*envy_lostak + rnorm(N, 0, 5)
ss_histak <- 2.*envy_histak + rnorm(N, 0, 5)

inequality <- as.factor(inequality)

stake_diff <- ss_histak - ss_lostak

ineq_data <- data.frame(pnum,inequality,envy_lostak,envy_histak,ss_lostak,ss_histak,stake_diff)
```

## Study 1a/1b/1c, Analysis Plan {.unnumbered}

```{r envy-measure, eval = F}
ineq_data$envy_lostak <- rowSums(ineq_data
    [,c("partner_envy_lostak", "partner_jealous_lostak", 
        "partner_frustrated_lostak", "partner_bitter_lostak")])

ineq_data$envy_histak <- rowSums(ineq_data
    [,c("partner_envy_histak", "partner_jealous_histak", 
        "partner_frustrated_histak", "partner_bitter_histak")])


# Acceptable if mean alpha >= .7
# Otherwise, iteratively dropping each item until
#>= .7 is achieved, minimum three items acceptable
# If no >= .7 solution found, forego mediation analyses
ltm::cronbach.alpha(ineq_data$envy_lostak,CI=TRUE)

ltm::cronbach.alpha(ineq_data$envy_histak,CI=TRUE)
```


```{r 1a-2b2w-long}
ineq_data %>% 
  gather(cell, value, ends_with("stak")) %>%
  mutate(stake_cond = str_sub(cell,1,end=-8),
         cell = str_sub(cell,-6,-1)) %>%
  # select(pnum, inequality, stake_cond, cell, value) %>%
  spread(key = cell, value = value)

ineq_data_long <- ineq_data %>% 
  gather(cell, value, ends_with("stak")) %>%
  mutate(stake_cond = str_sub(cell,1,end=-8),
         cell = str_sub(cell,-6,-1)) %>%
  # select(pnum, inequality, stake_cond, cell, value) %>%
  spread(key = stake_cond, value = value)

ineq_data_long <- rename(ineq_data_long, stake_cond=cell,
                         security_spending = ss,
                         likely_envy = envy)
```


```{r long-summary-security}
ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  get_summary_stats(security_spending, type = "mean_sd")

ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  identify_outliers(security_spending)

ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  shapiro_test(security_spending)

ggqqplot(ineq_data_long, "security_spending", ggtheme = theme_bw()) +
  facet_grid(inequality ~ stake_cond)

ineq_data_long %>%
  group_by(stake_cond) %>%
  levene_test(security_spending ~ inequality)

# homogeneity of covariances - only signals problems 
#when p < 0.001 and your sample sizes are unequal
# Fix:  separating your analyses into distinct 
#repeated measures ANOVAs for each group. 
#Alternatively, you could omit the 
#interpretation of the interaction term.
# At minimum. Report violation
box_m(ineq_data_long[, "security_spending", drop = FALSE], 
      ineq_data_long$inequality)
```


```{r long-summary-envy}
ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  get_summary_stats(likely_envy, type = "mean_sd")

ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  identify_outliers(likely_envy)

ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  shapiro_test(likely_envy)

ggqqplot(ineq_data_long, "likely_envy", ggtheme = theme_bw()) +
  facet_grid(inequality ~ stake_cond)

ineq_data_long %>%
  group_by(stake_cond) %>%
  levene_test(likely_envy ~ inequality)

# homogeneity of covariances - only signals problems 
#when p < 0.001 and your sample sizes are unequal
# Fix:  separating your analyses into distinct 
#repeated measures ANOVAs for each group. 
#Alternatively, you could omit the 
#interpretation of the interaction term.
# At minimum. Report violation
box_m(ineq_data_long[, "likely_envy", drop = FALSE], 
      ineq_data_long$inequality)
```

### Hypothesis 1  {.unnumbered}

**H1:** `r hypotheses[1]`, or in terms of the model: **H1:** `r h1.1`

```{r study1a-anova}
# By using the function get_anova_table() [rstatix] 
#to extract the ANOVA table, the Greenhouse-Geisser 
#sphericity correction is automatically applied to 
#factors violating the sphericity assumption.

ineq_anova_mixed <- anova_test(
  dv = security_spending, between= inequality, within = stake_cond, 
  wid=pnum, data = ineq_data_long
  )

get_anova_table(ineq_anova_mixed)
```


```{r afex-anova}
# Fit ANOVA ---------------------------------------------------------------

afex_options(es_aov         = 'ges',
             correction_aov = 'GG',
             emmeans_model  = 'univariate')

ez_inequality <- aov_ez(id='pnum',
                            dv='security_spending',
                            data=ineq_data_long,
                            within = c('stake_cond'),
                            between = c('inequality'))
ez_inequality


afex_plot(ez_inequality,  ~ inequality,  ~ stake_cond)
```


```{r group-lostak}
#this use of N looks right- for each between-subjects factor
grouped_lostak <- ineq_data %>%
  group_by(inequality) %>%
  summarise_at(vars(ss_lostak), list(mean = mean,sd=sd,n=length))

grouped_lostak$se <- grouped_lostak$sd/sqrt(grouped_lostak$n)

lostak_dif <- as.numeric(unname(grouped_lostak[2,2] - 
                                  grouped_lostak[1,2]))

lostak_se <- as.numeric(unname(sqrt(grouped_lostak[2,5] +
                                      grouped_lostak[1,5])))

lostak_diff_sd <- as.numeric(sqrt(grouped_lostak[2,5]^2 +
                                    grouped_lostak[1,5]^2))
```


```{r group-histak}
#this use of N looks right- for each between-subjects factor
grouped_histak <- ineq_data %>%
  group_by(inequality) %>%
  summarise_at(vars(ss_histak), list(mean = mean,sd=sd,n=length))

grouped_histak$se <- grouped_histak$sd/sqrt(grouped_histak$n)

histak_dif <- as.numeric(unname(grouped_histak[2,2] - 
                                  grouped_histak[1,2]))

histak_se <- as.numeric(unname(sqrt(grouped_histak[2,5] +
                                      grouped_histak[1,5])))

histak_diff_sd <- as.numeric(sqrt(grouped_histak[2,5]^2 +
                                    grouped_histak[1,5]^2))


```


```{r overall-equiv-computation}
#this use of N may be wrong - uses the overall 
#sample size instead of some specification from between groups 
diff_diff <- histak_dif - lostak_dif

diff_se <- sqrt(lostak_se+ histak_se)

pooled <- sqrt(((N-1)*histak_diff_sd^2 + 
                  (N-1)*lostak_diff_sd^2) / (N+N-2))

diff_sd <- diff_se*sqrt(N)

```


An equivalence test will be used to determine whether the effect of inequality significantly smaller than a minimally large effect size.

```{r t-tost}

tsum_TOST(
m1 = histak_dif,
sd1 = histak_diff_sd,
n1 = N,
m2 = lostak_dif,
sd2 = lostak_diff_sd,
n2 = N,
r12 = .5,
hypothesis = "EQU",
paired = TRUE,
var.equal = FALSE,
low_eqbound = -pooled*.2,
high_eqbound = pooled*.2,
mu = 0,
eqbound_type = "raw",
alpha = 0.05,
bias_correction = TRUE,
rm_correction = FALSE
)
```



**H1a)**: `r h1a`, or in terms of the model, **H1a)**: `r h1am`

**H1a.1)**, mediation step 1: `r h1a.1`


```{r study 1a-med-mixed}
m_mixed_med1 <- lmer(likely_envy ~ inequality  + (1| pnum) + 
                       stake_cond, data = ineq_data_long)

m_mixed_med2 <- lmer(security_spending ~ likely_envy + inequality  + 
                       (1| pnum) + stake_cond, data = ineq_data_long)

m_mixed_total <- lmer(security_spending ~ inequality  + (1| pnum) + 
                        stake_cond, data = ineq_data_long)

m_mixed_med_full <- mediate(m_mixed_med1, m_mixed_med2, 
    #                         boot = TRUE,   
    boot.ci.type = "bca", sims = 2000,
    treat="inequality",
                           mediator="likely_envy")


plot(m_mixed_med_full)
summary(m_mixed_med_full)



```


```{r t-testplot, include=FALSE}
bxp <- ggboxplot(
  ineq_data, x = "inequality", y = "security_spending", 
  ylab = "Security Spending", xlab = "Inequality", add = "jitter"
  )

ineq_t_test <- ineq_t_test %>% add_xy_position(x = "group")

bxp + 
  stat_pvalue_manual(ineq_t_test, tip.length = 0) +
  labs(subtitle = get_test_label(ineq_t_test, detailed = TRUE))

```


```{r mediat-predict}
#predicting mediator
m_envy_med1 <- lm(likely_envy ~ inequality, data = ineq_data)
```

**H1a.2)**, mediation step 2: `r h1a.2`

```{r two-lev-likely-security}
# test for relationship between p. attack likelihood and security spending
m_envy_med2 <- lm(security_spending ~ likely_envy + inequality, 
                  data = ineq_data)
```

**H1a.3)**, mediation step 3: `r h1a.3`

```{r two-lev-med}
# see https://ademos.people.uic.edu/
#Chapter15.html#41_create_the_necessary_regression_models

# ACME: Average Causal Mediation Effect [total effect - direct effect]
# ADE: Average Direct Effect [total effect - indirect effect]
# Total Effect: Direct (ADE) + Indirect (ACME)
# Prop. Mediated: Conceptually ACME / Total effect 
#(This tells us how much of the total effect 
#our indirect effect is 'explaining')

m_envy_med_full <- mediate(m_envy_med1, m_envy_med2, boot = TRUE,   
    boot.ci.type = "bca", sims = 2000,treat="inequality",
                           mediator="likely_envy")


plot(m_envy_med_full)
summary(m_envy_med_full)
```

## Study 1d, Analysis Plan {.unnumbered}

```{r merit-items, eval=FALSE}
ineq_data$likely_envy <- rowSums(ineq_data[,c("partner_envy", 
  "partner_jealous", "partner_frustrated", "partner_bitter")

ltm::cronbach.alpha(ineq_data$likely_envy,CI=TRUE)
# Acceptable if mean alpha >= .7
# Otherwise, try dropping each item until >= .7 is achieved
# If no >= .7 solution found, forego mediaiton analyses

reasonable_income_text <- "My partner's assigned income is reasonable"
fair_distribution_text <- "The way incomes were given for this game is fair"
deserved_income_text <- "I deserve my income for this game"
deserved_role_text <- "I deserve my role for this game"
```

```{r test-merit-data}
# Used for making test data
ineq_merit_data <- ineq_data

ineq_merit_data$merit <- sample(c(0,1), replace=TRUE, size=N)

ineq_merit_data$merit <- ifelse(ineq_merit_data$merit == 1,
                                "merit", "random")

ineq_merit_data$inequality <- ifelse(ineq_merit_data$inequality == 1,
                                     "unequal", "equal")

ineq_merit_data$inequality <- as.factor(ineq_merit_data$inequality)
ineq_merit_data$merit <- as.factor(ineq_merit_data$merit)
```

```{r fairness-manipulationcheck}
game_fair_text <- "The way incomes were given for this game is fair"
self_fair_text <-"My assigned income is fair"
other_fair_text <-"My partner's assigned income is fair"
```

### Hypothesis 2 {.unnumbered}

**H2)**: `r h2`. Or more precisely, **H2.1)**: `r h2.1`


```{r merit-assumptions}
outliers_merit <- ineq_merit_data %>%
  group_by(merit, inequality) %>%
  identify_outliers(security_spending)

# If outliers present, winzorize


# Build the linear model
lm_merit  <- lm(security_spending ~ as.factor(inequality)*as.factor(merit),
             data = ineq_merit_data)

# Create a QQ plot of residuals
qq_merit <- ggqqplot(residuals(lm_merit))

#shapiro normality
shap_merit <- shapiro_test(residuals(lm_merit))

#normality by groups
shap_g_merit <- ineq_merit_data %>%
  group_by(merit, inequality) %>%
  shapiro_test(security_spending)

# qqplot by group
qq_g_merit <- ggqqplot(ineq_merit_data,
                           "security_spending", ggtheme = theme_bw()) +
  facet_grid(inequality ~ merit)

# Due to large samples, no alternative method 
#will be used in the case of nonnormality

levene_merit <- ineq_merit_data %>% levene_test(security_spending ~ 
    as.factor(inequality)*as.factor(merit))

# Due to large samples, no alternative method will 
#be used in the case of heterogeneity of variance


# https://easystats.github.io/effectsize/articles/effectsize.html
# see above for 95%ci for eta squared
```

```{r merit-anova-lm, echo = FALSE}
# Method 1: stats::lm & car::Anova 
#fit model
lm_merit <- lm(security_spending ~ inequality*merit, data = ineq_merit_data)

#analyze model
car_lm_merit <- Anova(lm_merit)

#Summarize model
car_lm_sum <- anova_summary(car_lm_merit) 
```


```{r merit-anova-aov}
# Method 2: stats::aov  Best one to use 
#because the aov object goes on to mesh with tukey_hsd()
# fit model 
aov_merit <- aov(security_spending ~ inequality*merit, 
               data = ineq_merit_data)
#analyze model
car_aov_merit <- Anova(aov_merit)

#Summarize model
car_aov_sum <- anova_summary(car_aov_merit)
```

```{r merit-anova-anovatest, echo=FALSE}
# Method 3: rstatix::anova_test
anova_merit <- ineq_merit_data %>% anova_test(security_spending ~ 
                                                inequality*merit
# ,type = 3
)
```

**H2.2)**: `r h2.2`

```{r merit-pairwise}
#planned comparisons, using method 2
# tkmerit <- stats::TukeyHSD(aov_merit)
tukey_merit <- aov_merit  %>% tukey_hsd()


#provides main effects at different levels (simple main effects)
merit_mod <- ineq_merit_data %>%
  group_by(merit) %>%
  rstatix::emmeans_test(security_spending ~ inequality, 
                        p.adjust.method = "bonferroni")

```

```{r merit-plot, echo=FALSE}
#doesn't do multiple factors
# get_comparisons(res.aov)

merit_mod <- merit_mod %>% add_xy_position(x = "merit")

bxp <- ggboxplot(
  ineq_merit_data, x = "merit", y = "security_spending",
  color = "inequality", palette = "jco"
  )

#ggsignif?

    # only works using rstatix::anova_test method
bxp +
  stat_pvalue_manual(merit_mod) +
  labs(
    subtitle = get_test_label(anova_merit, detailed = TRUE),     
    caption = get_pwc_label(merit_mod)
    )
```

## Study 1e, Analysis Plan {.unnumbered}

### Hypothesis 3 {.unnumbered}


**H3):** `r h3`. Or more precisely, **H3.1):** `r h3.1`

```{r group-assumptions}
outliers_merit <- ineq_group_data %>%
  group_by(outgroup, inequality) %>%
  identify_outliers(security_spending)

# If outliers present, winzorize

# Build the linear model
lm_group  <- lm(security_spending ~ 
                  as.factor(inequality)*as.factor(outgroup),
             data = ineq_group_data)

# Create a QQ plot of residuals
qq_group <- ggqqplot(residuals(lm_group))

#shapiro normality
shap_merit <- shapiro_test(residuals(lm_merit))

#normality by groups
shap_g_merit <- ineq_group_data %>%
  group_by(outgroup, inequality) %>%
  shapiro_test(security_spending)

# qqplot by group
qq_g_group <- ggqqplot(ineq_group_data,
                           "security_spending", ggtheme = theme_bw()) +
  facet_grid(inequality ~ outgroup)

# Due to large samples, no alternative method will 
#be used in the case of nonnormality

levene_group <- ineq_group_data %>% levene_test(security_spending ~ 
    as.factor(inequality)*as.factor(outgroup))

# Due to large samples, no alternative method will be 
#used in the case of heterogeneity of variance
```


```{r group-aov}
aov_group <- aov(security_spending ~ as.factor(agentic)*as.factor(outgroup), 
               data = ineq_group_data, type="III")

#analyze model
car_aov_group <- Anova(aov_group)

#Summarize model
car_aov_group_sum <- anova_summary(car_aov_group)
```

**H3.2):** `r h3.2`

```{r group-tukey}
tukey_group <- stats::TukeyHSD(aov_group)

#provides main effects at different levels
library(emmeans)
group_mod <- ineq_group_data %>%
  group_by(merit) %>%
  emmeans_test(security_spending ~ inequality, 
               p.adjust.method = "bonferroni")
```


## Study 2 data screening {.unnumbered}

Although the ICVS, PWT, and SWIID extend across multiple years, the current analysis will be limited to observations across 2004-2006. These observations were collected across two distinct sweeps in the ICVS, with one being specific to the European Union. Imposing this restriction yields a sufficient initial number of cases (`r format(sweep5_nrow, big.mark = ",", scientific = FALSE)`) and countries (`r sweep5_countries`) before screening, combined with relative recency of data. By contrast, all data collected by the ICVS between 2010 and 2015 only totals only twelve countries, before screening.

Observations were excluded for participants that refused response on any analysis-relevant measures. Likewise, observations were dropped that had country-wide missing responses on any predictor and outcome measures. Such countries being dropped from analyses include Switzerland (missing security items) and Hong Kong (missing age).

Notably, the number of participants and countries dropped from analyses can be heavily impacted by the selection of variables targeted for analyses. For instance, including perceived police effectiveness in any analyses would require dropping the countries of Japan, Peru, and Iceland. Likewise, including participants' experiences of assault would require removing Peru. Lastly, analyzing participants' income quartiles requires removing Japan.

Dropping all three of these variables yields k = `r sum(summary(iv_2005$country)>0)` countries, and n = `r format(nrow(iv_2005), big.mark = ",", scientific = FALSE)` participants. By comparison, including these three variables yields a sample of `r sum(summary(iv_2005_mod$country)>0)` countries and a total `r format(nrow(iv_2005_mod), big.mark = ",", scientific = FALSE)` participants. The reported analyses will focus on the former, larger sample specification to avoid restricting the observed range of values. For instance, Peru has the highest reported rates of victimization in this sample, and the second-highest gini value.

## Study  2 Analysis
Main analyses will be conducted with the following model specification using the r package `ordinal`:

`r sec_mord_min`