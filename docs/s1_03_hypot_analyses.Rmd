---
title: "s1_03_hypot_analyses"
author: "Dallas Novakowski"
date: "20/01/2022"
output: html_document
---

```{r hypot-setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)


library(tidyverse)
library(kableExtra)
library(lme4)
library(rstatix)  # t_test
library(stats)  #aov function
library(ggpubr)  #ggqqplot


library(mediation)
mediate <- mediation::mediate

library(emmeans)

source(here::here("scripts","hypotheses.R"), local = knitr::knit_global())
source(here::here("scripts","measures.R"), local = knitr::knit_global())
```

```{r testdata,echo=FALSE}
#used for 
set.seed(1234) #Standardizes the numbers generated by rnorm; see Chapter 5
N <- 200 #Number of participants; graduate students
inequality <- sample(c(0,1), replace=TRUE, size=N)
pnum <- seq_len(N)

stake_strings <- c("histak_loprob_loprice", "histak_loprob_hiprice", "histak_hiprob",
"lostak_loprob_loprice", "lostak_loprob_hiprice", "lostak_hiprob") 

# stake <- as.factor(sample(stake_strings, replace=TRUE, size=N))

likely_envy <- round(1+1.5*inequality + rnorm(N, 0,2),2) #Suspected mediator 

envy_lostak_loprob_loprice <- 2*likely_envy + rnorm(N, 0, 5)

envy_lostak_loprob_hiprice <- 2*likely_envy + rnorm(N, 0, 5)

envy_lostak_hiprob <- 2*likely_envy + rnorm(N, 0, 5)

envy_histak_loprob_loprice <- 2*likely_envy + rnorm(N, 0, 5)

envy_histak_loprob_hiprice <- 2*likely_envy + rnorm(N, 0, 5)

envy_histak_hiprob <- 2*likely_envy + rnorm(N, 0, 5)

security_spending <- 2*likely_envy + rnorm(N, 0, 5) #DV

ss_lostak_loprob_loprice <- 2*likely_envy + rnorm(N, 0, 5)

ss_lostak_loprob_hiprice <- 2*likely_envy + rnorm(N, 0, 5)

ss_lostak_hiprob <- 2*likely_envy + rnorm(N, 0, 5)

ss_histak_loprob_loprice <- 2*likely_envy + rnorm(N, 0, 5)

ss_histak_loprob_hiprice <- 2*likely_envy + rnorm(N, 0, 5)

ss_histak_hiprob <- 2*likely_envy + rnorm(N, 0, 5)


inequality <- as.factor(inequality)

ineq_data <- data.frame(pnum,inequality, stake, likely_envy, security_spending, ss_lostak_loprob_loprice, ss_lostak_loprob_hiprice, ss_lostak_hiprob,ss_histak_loprob_loprice, ss_histak_loprob_hiprice, ss_histak_hiprob,
                        envy_lostak_loprob_loprice, envy_lostak_loprob_hiprice, envy_lostak_hiprob,envy_histak_loprob_loprice, envy_histak_loprob_hiprice, envy_histak_hiprob
                        )
```

## Study 1a/1b/1c, Analysis Plan {.unnumbered}

```{r envy-measure}
ineq_data$likely_envy <- rowSums(ineq_data
    [,c("partner_envy", "partner_jealous", "partner_frustrated", 
        "partner_bitter")])


# Acceptable if mean alpha >= .7
# Otherwise, iteratively dropping each item until
#>= .7 is achieved, minimum three items acceptable
# If no >= .7 solution found, forego mediation analyses
ltm::cronbach.alpha(ineq_data$likely_envy,CI=TRUE)
```




```{r study-1a-assumptions}
# Outliers
ineq_data %>%
  group_by(inequality) %>%
  identify_outliers(security_spending)

# If outliers present, winzorize

#shapiro normality by group
ineq_data %>%
  group_by(inequality) %>%
  shapiro_test(security_spending)

ggqqplot(ineq_data, x = "security_spending", facet.by = "inequality")

# Due to large samples, no alternative method will 
# be used in the case of nonnormality

ineq_data %>% levene_test(security_spending ~ as.factor(inequality))

# If levene's is significant, use welch's t-test

```

```{r t-test}

#welch's
ineq_t_test <- ineq_data %>% 
  t_test(security_spending ~ inequality) %>%
  add_significance()
ineq_t_test

ineq_data %>%  cohens_d(security_spending ~ inequality, var.equal = FALSE)

# student's (equal variances)
ineq_t_test_stud <- ineq_data %>%
  t_test(security_spending ~ inequality, var.equal = TRUE) %>%
  add_significance()
ineq_t_test_stud

ineq_data %>%  cohens_d(security_spending ~ inequality, var.equal = TRUE)
```


```{r 1a-long}
ineq_data_long <- ineq_data %>%
  gather(key = "stake_cond", value = "security_spending",
         ss_lostak_loprob_loprice, ss_lostak_loprob_hiprice, 
         ss_lostak_hiprob,ss_histak_loprob_loprice, 
         ss_histak_loprob_hiprice, ss_histak_hiprob) %>%
  convert_as_factor(pnum, stake_cond)

ineq_envy_long <- ineq_data %>%
  gather(key = "stake_cond", value = "likely_envy", 
         envy_lostak_loprob_loprice, envy_lostak_loprob_hiprice, 
         envy_lostak_hiprob,envy_histak_loprob_loprice, 
         envy_histak_loprob_hiprice, envy_histak_hiprob) %>%
  convert_as_factor(pnum, stake_cond)

ineq_data_long$likely_envy <- ineq_envy_long$likely_envy

ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  get_summary_stats(security_spending, type = "mean_sd")

ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  identify_outliers(security_spending)

ineq_data_long %>%
  group_by(stake_cond, inequality) %>%
  shapiro_test(security_spending)

ggqqplot(ineq_data_long, "security_spending", ggtheme = theme_bw()) +
  facet_grid(inequality ~ stake_cond)

ineq_data_long %>%
  group_by(stake_cond) %>%
  levene_test(security_spending ~ inequality)

# homogeneity of covariances - only signals problems 
#when p < 0.001 and your sample sizes are unequal
# Fix:  separating your analyses into distinct 
#repeated measures ANOVAs for each group. 
#Alternatively, you could omit the 
#interpretation of the interaction term.
# At minimum. Report violation
box_m(ineq_data_long[, "security_spending", drop = FALSE], 
      ineq_data_long$inequality)
```

### Hypothesis 1 

**H1:** `r hypotheses[1]`, or in terms of the model: **H1:** `r h1.1`

```{r study1a-anova}
# By using the function get_anova_table() [rstatix] 
#to extract the ANOVA table, the Greenhouse-Geisser 
#sphericity correction is automatically applied to 
#factors violating the sphericity assumption.

ineq_anova_mixed <- anova_test(
  dv = security_spending, between= inequality, within = stake_cond, 
  wid=pnum, data = ineq_data_long
  )

get_anova_table(ineq_anova_mixed)

```


**H1a)**: `r h1a`, or in terms of the model, **H1a)**: `r h1am`

**H1a.1)**, mediation step 1: `r h1a.1`


```{r study 1a-med-mixed}
m_mixed_med1 <- lmer(likely_envy ~ inequality  + (1| pnum) + 
                       stake_cond, data = ineq_data_long)

m_mixed_med2 <- lmer(security_spending ~ likely_envy + inequality  + 
                       (1| pnum) + stake_cond, data = ineq_data_long)

m_mixed_total <- lmer(security_spending ~ inequality  + (1| pnum) + 
                        stake_cond, data = ineq_data_long)

m_mixed_med_full <- mediate(m_mixed_med1, m_mixed_med2, 
    #                         boot = TRUE,   
    boot.ci.type = "bca", sims = 2000,
    treat="inequality",
                           mediator="likely_envy")


plot(m_mixed_med_full)
summary(m_mixed_med_full)



```


```{r t-testplot, include=FALSE}
bxp <- ggboxplot(
  ineq_data, x = "inequality", y = "security_spending", 
  ylab = "Security Spending", xlab = "Inequality", add = "jitter"
  )

ineq_t_test <- ineq_t_test %>% add_xy_position(x = "group")

bxp + 
  stat_pvalue_manual(ineq_t_test, tip.length = 0) +
  labs(subtitle = get_test_label(ineq_t_test, detailed = TRUE))

```


```{r mediat-predict}
#predicting mediator
m_envy_med1 <- lm(likely_envy ~ inequality, data = ineq_data)
```

**H1a.2)**, mediation step 2: `r h1a.2`

```{r two-lev-likely-security}
# test for relationship between p. attack likelihood and security spending
m_envy_med2 <- lm(security_spending ~ likely_envy + inequality, 
                  data = ineq_data)
```

**H1a.3)**, mediation step 3: `r h1a.3`

```{r two-lev-med}
# see https://ademos.people.uic.edu/
#Chapter15.html#41_create_the_necessary_regression_models

# ACME: Average Causal Mediation Effect [total effect - direct effect]
# ADE: Average Direct Effect [total effect - indirect effect]
# Total Effect: Direct (ADE) + Indirect (ACME)
# Prop. Mediated: Conceptually ACME / Total effect 
#(This tells us how much of the total effect 
#our indirect effect is 'explaining')

m_envy_med_full <- mediate(m_envy_med1, m_envy_med2, boot = TRUE,   
    boot.ci.type = "bca", sims = 2000,treat="inequality",
                           mediator="likely_envy")


plot(m_envy_med_full)
summary(m_envy_med_full)
```

## Study 1d, Analysis Plan {.unnumbered}

```{r merit-items, eval=FALSE}
ineq_data$likely_envy <- rowSums(ineq_data[,c("partner_envy", 
  "partner_jealous", "partner_frustrated", "partner_bitter")

ltm::cronbach.alpha(ineq_data$likely_envy,CI=TRUE)
# Acceptable if mean alpha >= .7
# Otherwise, try dropping each item until >= .7 is achieved
# If no >= .7 solution found, forego mediaiton analyses

reasonable_income_text <- "My partner's assigned income is reasonable"
fair_distribution_text <- "The way incomes were given for this game is fair"
deserved_income_text <- "I deserve my income for this game"
deserved_role_text <- "I deserve my role for this game"
```

```{r test-merit-data}
# Used for making test data
ineq_merit_data <- ineq_data

ineq_merit_data$merit <- sample(c(0,1), replace=TRUE, size=N)

ineq_merit_data$merit <- ifelse(ineq_merit_data$merit == 1,
                                "merit", "random")

ineq_merit_data$inequality <- ifelse(ineq_merit_data$inequality == 1,
                                     "unequal", "equal")

ineq_merit_data$inequality <- as.factor(ineq_merit_data$inequality)
ineq_merit_data$merit <- as.factor(ineq_merit_data$merit)
```

```{r fairness-manipulationcheck}
game_fair_text <- "The way incomes were given for this game is fair"
self_fair_text <-"My assigned income is fair"
other_fair_text <-"My partner's assigned income is fair"
```


**H2)**: `r h2`. Or more precisely, **H2.1)**: `r h2.1`


```{r merit-assumptions}
outliers_merit <- ineq_merit_data %>%
  group_by(merit, inequality) %>%
  identify_outliers(security_spending)

# If outliers present, winzorize


# Build the linear model
lm_merit  <- lm(security_spending ~ as.factor(inequality)*as.factor(merit),
             data = ineq_merit_data)

# Create a QQ plot of residuals
qq_merit <- ggqqplot(residuals(lm_merit))

#shapiro normality
shap_merit <- shapiro_test(residuals(lm_merit))

#normality by groups
shap_g_merit <- ineq_merit_data %>%
  group_by(merit, inequality) %>%
  shapiro_test(security_spending)

# qqplot by group
qq_g_merit <- ggqqplot(ineq_merit_data,
                           "security_spending", ggtheme = theme_bw()) +
  facet_grid(inequality ~ merit)

# Due to large samples, no alternative method 
#will be used in the case of nonnormality

levene_merit <- ineq_merit_data %>% levene_test(security_spending ~ 
    as.factor(inequality)*as.factor(merit))

# Due to large samples, no alternative method will 
#be used in the case of heterogeneity of variance


# https://easystats.github.io/effectsize/articles/effectsize.html
# see above for 95%ci for eta squared
```

```{r merit-anova-lm, echo = FALSE}
# Method 1: stats::lm & car::Anova 
#fit model
lm_merit <- lm(security_spending ~ inequality*merit, data = ineq_merit_data)

#analyze model
car_lm_merit <- Anova(lm_merit)

#Summarize model
car_lm_sum <- anova_summary(car_lm_merit) 
```


```{r merit-anova-aov}
# Method 2: stats::aov  Best one to use 
#because the aov object goes on to mesh with tukey_hsd()
# fit model 
aov_merit <- aov(security_spending ~ inequality*merit, 
               data = ineq_merit_data)
#analyze model
car_aov_merit <- Anova(aov_merit)

#Summarize model
car_aov_sum <- anova_summary(car_aov_merit)
```

```{r merit-anova-anovatest, echo=FALSE}
# Method 3: rstatix::anova_test
anova_merit <- ineq_merit_data %>% anova_test(security_spending ~ 
                                                inequality*merit
# ,type = 3
)
```

**H2.2)**: `r h2.2`

```{r merit-pairwise}
#planned comparisons, using method 2
# tkmerit <- stats::TukeyHSD(aov_merit)
tukey_merit <- aov_merit  %>% tukey_hsd()


#provides main effects at different levels (simple main effects)
merit_mod <- ineq_merit_data %>%
  group_by(merit) %>%
  rstatix::emmeans_test(security_spending ~ inequality, 
                        p.adjust.method = "bonferroni")

```

```{r merit-plot, echo=FALSE}
#doesn't do multiple factors
# get_comparisons(res.aov)

merit_mod <- merit_mod %>% add_xy_position(x = "merit")

bxp <- ggboxplot(
  ineq_merit_data, x = "merit", y = "security_spending",
  color = "inequality", palette = "jco"
  )

#ggsignif?

    # only works using rstatix::anova_test method
bxp +
  stat_pvalue_manual(merit_mod) +
  labs(
    subtitle = get_test_label(anova_merit, detailed = TRUE),     
    caption = get_pwc_label(merit_mod)
    )
```

## Study 1e, Analysis Plan {.unnumbered}

**H3):** `r h3`. Or more precisely, **H3.1):** `r h3.1`

```{r group-assumptions}
outliers_merit <- ineq_group_data %>%
  group_by(outgroup, inequality) %>%
  identify_outliers(security_spending)

# If outliers present, winzorize

# Build the linear model
lm_group  <- lm(security_spending ~ 
                  as.factor(inequality)*as.factor(outgroup),
             data = ineq_group_data)

# Create a QQ plot of residuals
qq_group <- ggqqplot(residuals(lm_group))

#shapiro normality
shap_merit <- shapiro_test(residuals(lm_merit))

#normality by groups
shap_g_merit <- ineq_group_data %>%
  group_by(outgroup, inequality) %>%
  shapiro_test(security_spending)

# qqplot by group
qq_g_group <- ggqqplot(ineq_group_data,
                           "security_spending", ggtheme = theme_bw()) +
  facet_grid(inequality ~ outgroup)

# Due to large samples, no alternative method will 
#be used in the case of nonnormality

levene_group <- ineq_group_data %>% levene_test(security_spending ~ 
    as.factor(inequality)*as.factor(outgroup))

# Due to large samples, no alternative method will be 
#used in the case of heterogeneity of variance
```


```{r group-aov}
aov_group <- aov(security_spending ~ as.factor(agentic)*as.factor(outgroup), 
               data = ineq_group_data, type="III")

#analyze model
car_aov_group <- Anova(aov_group)

#Summarize model
car_aov_group_sum <- anova_summary(car_aov_group)
```

**H3.2):** `r h3.2`

```{r group-tukey}
tukey_group <- stats::TukeyHSD(aov_group)

#provides main effects at different levels
library(emmeans)
group_mod <- ineq_group_data %>%
  group_by(merit) %>%
  emmeans_test(security_spending ~ inequality, 
               p.adjust.method = "bonferroni")
```

