---
title: "02_security_power_analyses"
author: "Dallas Novakowski"
date: "15/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(gtable)
library(Superpower)
library(gridExtra)
set.seed(1234)

load(here::here("output", "pretest_output.RData"))

Superpower_options("plot" = FALSE, "verbose" = FALSE) 

nsims <- 2000

base_mean <- unname(base_mean)

cgwtools::resave(nsims, base_mean, file = here::here("output", "pretest_output.RData"))


```

After the pretest, we found substantial variation within conditions. From data vizualization, a few strategies can be identified for guiding consumption of security goods: firstly, purchasing none at all (the most risk-accepting strategy), secondly, purchasing the maximum possible, and third, purchasing the median value of the possible range. Lastly, for those that do not use one of these max/min/median strategies, participants seem to make purchases in multiples of five.

![](C:/Users/dalla/Google Drive/project_files/inequality_security/figures/spending_pretest_splitplot.png){width="60%"}

For this project, we will be using values from the 50_02 condition, which corresponds to a baseline 50% chance of successful thefts, and each unit of security costing \$0.02. This condition seems to produce the least skewed data, at `r round(base_skew,2)`.

The following document details power analyses using R package Superpower conducted to find adequately-powered sample sizes at varying effect sizes.

A major benefit of having run a pilot study is getting information on mean and standard deviation for our variables. It is generally uninformative to conduct a power analysis without these values, particularly the sd. Here, we can use a baseline average security consumption of `r round(base_mean,2)` units , with a standard deviation of `r round(base_sd,2)`.



# Two-level

```{r}
library(pwr)

#The `alternative` argument says we think the alternative is “greater” than the null, not just different.
power_ttest_security <- pwr.t.test(d=(0.6798-base_mean)/base_sd,power=.95,sig.level=.05,
           type="two.sample",alternative="greater")

power_ttest_security2 <- pwr.t.test(d=.2,power=.95,sig.level=.05,
           type="two.sample",alternative="greater")

power_ttest_security2_8 <- pwr.t.test(d=.2,power=.8,sig.level=.05,
           type="two.sample",alternative="greater")

eta01_power_ttest_security<- pwr.t.test(d=(0.7419-base_mean)/base_sd,power=.95,sig.level=.05,
           type="two.sample",alternative="greater")

pwr.anova.test(
  # n = 541.7865,
              power=.95,
               k = 2,
               f = .1,
               sig.level = .05)


power_ttest_security

cgwtools::resave(power_ttest_security,eta01_power_ttest_security, file = here::here("output", "pretest_output.RData"))

# Is there a way to convert partial eta^2 to cohen's d for repeated measures designs? I ask because I am conducting a meta-analysis and need to convert the studies' results into a common effect size. I read that it can be calculated in 2 steps: first cohen's f and then cohen's d.
#(1) cohen's f can be calculated from partial eta^2 as follows:
#cohen's f = sqrt(partialeta^2/1-partialeta^2)
#(2) cohen's f can be converted to cohen's d as follows:
#cohen's d = f*2


# d_to_peta <- function(d,n){
#   (d^2*n)/(d^2*n+n-1)
# }

d_to_peta <- function(d){
  f = (d/2)
  f^2/(f^2+1)
}
 
d_to_peta(power_ttest_security$d) 
  

```




```{r l2design, warning=FALSE}
# m_units = 37.1
# detecting .01 partial η2, with 95% power
l2security_01_design <- ANOVA_design(design = "2b",
                   n = 646, 
                   mu = c(0.6798, base_mean), 
                   sd = base_sd, 
                   # r = 0.8, 
                   labelnames = c("inequality", "yes", "no"))

ggplot2::ggsave(here::here("figures", "l2_design_plot.png"), height = 3, width =5)
```


```{r l2powerplot-01, warning=FALSE, echo=FALSE}
l2security_01_powerplot <- plot_power(l2security_01_design, min_n = 20, max_n = 700, desired_power = 95)

l2cell_n_01 <- l2security_01_powerplot$anova_n$n[1]

cgwtools::resave(l2cell_n_01, file = here::here("output", "pretest_output.RData"))


l2security_01_powerplot$plot_ANOVA

l2d <-ggplot2:: ggplot_build(l2security_01_powerplot$plot_ANOVA)


ggplot2::ggsave(here::here("figures", "l2powerplot.png"), height = 3, width =5)
```

```{r l2exact, warning=FALSE, echo=FALSE}

# security_01_power <- ANOVA_power(security_01_design, 
#                                   alpha = 0.05, 
#                                   nsims = nsims, 
#                                   seed = 1234)
# 
# knitr::kable(confint(security_01_power, level = .98))


l2_01_exact <- ANOVA_exact(l2security_01_design, 
                                  alpha = 0.05)


cgwtools::resave(l2_01_exact, file = here::here("output", "pretest_output.RData"))


knitr::kable(l2_01_exact$main_results)
```


# 2x2 factorial

## Trial 1: partial η2 = .05

```{r power 05, warning = FALSE}
# mean security consumed = 45.4
# detecting .05 partial η2, with 95% power
security_05_design <- ANOVA_design(design = "2b*2b",
                   n = 65, 
                   mu = c(0.908, base_mean, base_mean, base_mean), 
                   sd = base_sd, 
                   # r = 0.8, 
                   labelnames = c("inequality", "yes", "no", "undeserved", "yes", "no"),
                   plot = TRUE)


ggplot2::ggsave(here::here("figures", "power_design_plot.png"), height = 3, width =5)
```

It is worth noting that this design constitutes a ["no-way" interaction,](https://aaroncaldwell.us/SuperpowerBook/the-no-way-interactions.html) which "requires at least twice as many subjects per cell as a study that simply aims to show the simple effect." This requirement follows ["because we are testing the reduction of that same effect"](http://datacolada.org/17).

```{r powerplot 05, warning=FALSE, echo=FALSE}
security_05_powerplot <- plot_power(security_05_design, min_n = 20, max_n = 200, desired_power = 95)

# security_05_powerplot$anova_n$n[3]

security_05_powerplot$plot_ANOVA
```

> According to Cohen's (1988) guidelines, f2≥ 0.02, f2≥ 0.15, and f2 ≥ 0.35 represent small, medium, and large effect sizes, respectively.

> for eta square Basic rules of thumb are that: η2 = 0.01, indicates small effect; η2 = 0.06, medium effect; η2 = 0.14 large effect.

```{r power summary05, warning=FALSE, echo=FALSE}
# security_05_power <- ANOVA_power(security_05_design, 
#                                   alpha = 0.05, 
#                                   nsims = nsims, 
#                                   seed = 1234)
# 
# knitr::kable(confint(security_05_power, level = .98))

security_05_exact <- ANOVA_exact(security_05_design, 
                                  alpha = 0.05)

knitr::kable(security_05_exact$main_results)
```

Also following from the no-way interaction, each coefficient has the same effect size.

<!-- > [The interaction tests whether the average effect of hunger on liking fruit differs in the presence of bananas. In the presence of bananas the effect of hunger on the desireability of fruit is 5 scalepoints. The average effect (that we get from the marginal means) of hunger on fruit desireability is 2.5 (22.5-20). In other words, the interaction tests whether the difference effect between hunger and no hunger is different in the presence of an apple versus in the presence of a banana.](https://aaroncaldwell.us/SuperpowerBook/the-no-way-interactions.html) -->

## Trial 2: partial η2 = .01

```{r power 01, warning=FALSE}
# m_units = 37.1
# detecting .01 partial η2, with 95% power
security_01_design <- ANOVA_design(design = "2b*2b",
                   n = 340, 
                   mu = c(0.7419, base_mean, base_mean, base_mean), 
                   sd = base_sd, 
                   # r = 0.8, 
                   labelnames = c("inequality", "yes", "no", "undeserved", "yes", "no"))
```


```{r powerplot 01, warning=FALSE, echo=FALSE}
security_01_powerplot <- plot_power(security_01_design, min_n = 20, max_n = 500, desired_power = 95)

cell_n_01 <- security_01_powerplot$anova_n$n[1]

cgwtools::resave(cell_n_01, file = here::here("output", "pretest_output.RData"))


security_01_powerplot$plot_ANOVA

d <-ggplot2:: ggplot_build(security_01_powerplot$plot_ANOVA)

# security_01_powerplot$anova_n$n[3]
# 
# fplot <- security_01_powerplot$plot_ANOVA
# 
# 
# # Rows and columns can be dropped from the layout.
# 
# 
# g1 = ggplot2::ggplotGrob(fplot)
# 
# # To show the layout:
# gtable::gtable_show_layout(g1)
# 
# # Which columns (and/or rows) to drop?
# # In this case drop columns 5 and 6 to leave am = 0 plot
# # Drop columns 4 and 5 to leave am = 1 plot
# 
# # am = 0 plot
# g1_am0 = g1[-c(7,9),]
# 
# library(grid)
# p <-  grid.newpage()
# p <- grid.draw(g1_am0)
# 
# p

ggplot2::ggsave(here::here("figures", "01powerplot.png"), height = 3, width =5)
```

```{r power plot01, warning=FALSE, echo=FALSE}

# security_01_power <- ANOVA_power(security_01_design, 
#                                   alpha = 0.05, 
#                                   nsims = nsims, 
#                                   seed = 1234)
# 
# knitr::kable(confint(security_01_power, level = .98))


security_01_exact <- ANOVA_exact(security_01_design, 
                                  alpha = 0.05)


cgwtools::resave(security_01_exact, file = here::here("output", "pretest_output.RData"))


knitr::kable(security_01_exact$main_results)
```

## Trial 3: partial η2 = .02

```{r power 02, warning=FALSE}
#units = 39.8
# detecting .01 partial η2, with 95% power
security_02_design <- ANOVA_design(design = "2b*2b",
                   n = 168, 
                   mu = c(0.7959, base_mean, base_mean, base_mean), 
                   sd = base_sd, 
                   # r = 0.8, 
                   labelnames = c("inequality", "yes", "no", "undeserved", "yes", "no"))
```

```{r powerplot 02, warning=FALSE, echo=FALSE}
security_02_powerplot <- plot_power(security_02_design, min_n = 20, max_n = 500, desired_power = 95)

# security_02_powerplot$anova_n$n[3]

security_02_powerplot$plot_ANOVA
```

```{r power plot02, warning=FALSE, echo=FALSE}

# security_01_power <- ANOVA_power(security_01_design, 
#                                   alpha = 0.05, 
#                                   nsims = nsims, 
#                                   seed = 1234)
# 
# knitr::kable(confint(security_01_power, level = .98))


security_02_exact <- ANOVA_exact(security_02_design, 
                                  alpha = 0.05)

knitr::kable(security_02_exact$main_results)
```

# 2bx2wx2w factorial

First one yields a cohen's f of .2, which would be a cohen's d of .4

# For a larger mixed effect: cohen's f = .2

```{r mixed-power-f2, warning=FALSE}
# m_units = 37.1

# .65 -> f=.109

security_mixed_design_f2 <- ANOVA_design(design = "2b*2w*2w",
                   n = 163, 
                   mu = c(0.6798,0.6798, 0.6798, 0.6798, base_mean, base_mean, base_mean, base_mean), 
                   sd = base_sd, 
                   r = pretest_icc$ICC_adjusted,
                   labelnames = c("inequality", "yes", "no", 
                                  "stake", "hi", "lo"
                                  , "prob", "hi prob", "lo prob"
                                  # ,"price" , "hi", "lo"
                                  ))

ggplot2::ggsave(here::here("figures", "power_design_within_f2.png"), height = 3, width =5)

security_mixed_design_f2
```


```{r mixed-powerplot-f2, warning=FALSE, echo=FALSE}
security_mixed_powerplot_f2 <- plot_power(security_mixed_design_f2, min_n = 20, max_n = 500, 
                                       desired_power = 95)

cell_n_mixed_f2 <- security_mixed_powerplot_f2$anova_n$n[1]

cgwtools::resave(cell_n_mixed_f2, file = here::here("output", "pretest_output.RData"))

security_mixed_powerplot_f2$plot_ANOVA
g1_f2 <- ggplotGrob(security_mixed_powerplot_f2$plot_ANOVA)

gtable_show_layout(g1_f2)

grid_ineq_extract_f2 = g1_f2[c(7,20:24),]

mixed_ineq_grid_f2  <- grid.arrange(grid_ineq_extract_f2)
# Export
ggsave(filename=here::here("figures","mixedpowerplot_f2.png"), plot=mixed_ineq_grid_f2, height = 3)
```


```{r power-plot-f2, warning=FALSE, echo=FALSE}
security_mixed_exact_f2 <- ANOVA_exact(security_mixed_design_f2, 
                                  alpha = 0.05)

cgwtools::resave(security_mixed_exact_f2, file = here::here("output", "pretest_output.RData"))

knitr::kable(security_mixed_exact_f2$main_results)
```

# Smaller mixed effect: cohen's f = .1


```{r mixed-power-f1, warning=FALSE}
# m_units = 37.1

# .65 -> f=.109

# detecting .01 partial η2, with 95% power
security_mixed_design <- ANOVA_design(design = "2b*2w*2w",
                   n = 653, 
                   mu = c(0.647,0.647, 0.647, 0.647, base_mean, base_mean, base_mean, base_mean), 
                   sd = base_sd, 
                   r = pretest_icc$ICC_adjusted,
                   labelnames = c("inequality", "yes", "no", 
                                  "stake", "hi", "lo"
                                  , "prob", "hi prob", "lo prob"
                                  # ,"price" , "hi", "lo"
                                  ))

ggplot2::ggsave(here::here("figures", "power_design_within.png"), height = 3, width =5)

security_mixed_design
```


```{r mixedpowerplot-f1, warning=FALSE, echo=FALSE}
security_mixed_powerplot <- plot_power(security_mixed_design, min_n = 20, max_n = 700, 
                                       desired_power = 95)

cell_n_mixed <- security_mixed_powerplot$anova_n$n[1]

cgwtools::resave(cell_n_mixed, file = here::here("output", "pretest_output.RData"))

security_mixed_powerplot$plot_ANOVA
g1 <- ggplotGrob(security_mixed_powerplot$plot_ANOVA)

gtable_show_layout(g1)

grid_ineq_extract = g1[c(7,20:24),]

mixed_ineq_grid  <- grid.arrange(grid_ineq_extract)
# Export
ggsave(filename=here::here("figures","mixedpowerplot.png"), plot=mixed_ineq_grid, height = 3)
```


```{r power-table-f1, warning=FALSE, echo=FALSE}
security_mixed_exact <- ANOVA_exact(security_mixed_design, 
                                  alpha = 0.05)

cgwtools::resave(security_mixed_exact, file = here::here("output", "pretest_output.RData"))

knitr::kable(security_mixed_exact$main_results)
```

http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/

> The crucial thing to recognize about applying the classical Cohen’s d is that it deliberately ignores information about the design of the study. That is, you compute d the same way whether you are dealing with a between-subjects, within-subjects, or mixed design. Basically, in computing d, you always treat the data as if it came from a simple two-independent-groups design.