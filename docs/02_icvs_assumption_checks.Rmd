---
title: "ICVS exploration, assumption check, and contingency procedure"
output: 
  html_document:
    number_sections: true
    toc: true
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse) # pipe
library(purrr) # map function
library(car) #qqPlot
library(survey)
# library(nloptr) # for bobyqa used in svy2lme

library(WeMix)
library(Statamarkdown)

load("C:/Users/dalla/Google Drive/data_files/icvs_pwt_swiid/data/iv_2005.RData")

source("C:/Users/dalla/Google Drive/project_files/icvs_inequality/scripts/icvs_scripts.r", local = knitr::knit_global())

iv_2005_mod <- iv_2005_mod %>% 
        filter(!is.na(num_victim_5yr))
```

# At a glance

<!--# useful tutorials at https://www.juliapilowsky.com/2018/10/19/a-practical-guide-to-mixed-models-in-r/ -->

The purpose of this section is to outline the branches of how this data will be explored and modified depending on various assumption checks. This a priori examiniation is particularly important given the substantial degrees of freedom that comes with analyzing archival data, allowing a researcher to pick and choose those data and analyses that best suit their preferred story (simmons et al., 2011).

The following describes two survey sweeps of the International Crime Victimization Survey conducted across 2004-6. At first, this data had `r sweep5_nrow` respondents and `r sweep5_countries` countries. After a exclusion process maximizing the number of countries and observations, there were 31 countries with 85,085 participants, with a minimum of 790 participants per country. An exclusion strategy maximizing the number of variables yields 27 countries, and 48,671 participants.

The following and planned analyses will be carried out with `r sum(summary(iv_2005_mod$country)>0)` countries, and `r format(nrow(iv_2005_mod), big.mark = ",", scientific = FALSE)` participants.

If the assumptions underlying a multilevel regression hold in this dataset, the analysis will be conducted using maximum likelihood estimates (MLE) in Stata (IC 14.2; REF), as there are a relatively small number of level-2 units in this data. Likewise, the use of full maximum lilkelihood will enable the use of statistical weights to increase the representativeness of the available data.

## Analysis plan

I would prefer to use an r package for my analyses (lme4, EdSurvey, WeMix, BIFIEsurvey ). However, throughout this screening process, lme4 ran into convergence problems (particularly when incorporating survey weights). Likewise the other packages are so new and specific that they don't generate objects that can be used for analyses like cook's distance.

By contrast, Stata is far more developed for multilevel analysis with survey weights. For instance, it provides model-wide Cook's D values for just level-2 units, whereas R can do it only after making a new dataset. If we are going to use a package that has poor integration with rmarkdown, we might as well use the program that best handles the statistics, and save ambitions for a reproducible manuscript for later projects.

<!--# The relationship between country-level inequality and the consumption of security products will be tested using a multilevel linear regression. This analysis will be accomplished using a combination of three archival datasets. Firstly, indicators of security consumption have been accessed from the International Crime Victimization survey (ICVS; REF), which is an accumulation of standardized sample surveys to look at householders' experiences with crime, policing, crime prevention and feelings of unsafety. Although it does not consist of longitudinal observations, the ICVS has been distributed across five phases over fifteen years (1989, 1992, 1996, 2000, 2005), totaling 300,000 people and 78 different countries (Data Archiving and Networked Services, n.d.). For the purposes of this study, it is most notable that this survey contains items such as respondents' adopted measures to protect themselves against burglary. Secondly, nation-level inequality in disposable income was accessed through the Standardized World Income Inequality Database (SWIID; REF). The SWIID has been designed to maximize the comparability of income inequality data while maintaining the widest possible coverage across countries and over time. As a result, the gini coefficients are accompanied by standard errors to reflect uncertainty in the estimates. Lastly, countries' expenditure-side real GDP was retrieved from the Penn World Table, version 10.0 (PWT; REF). The selected GDP values are adjusted for Purchasing Power Parity, "to compare relative living standards across countries at a single point in time" (https://www.rug.nl/ggdc/productivity/pwt/?lang=en). Nations' GDP values were divided by their population sizes to yield a per-capita GDP value, which will be used for these analysis.Although the above datasets extend across multiple years, the current analysis will be limited to observations across 2004-2006. Imposing this restriction allows for a sufficient number of countries, combined with relative recency of data. After a conservative exclusion process for missing data, survey sweeps conducted across 2004-6 yielded 31 countries with 85,085 participants, with a minimum of 790 participants per country. An exclusion strategy maximizing the number of variables yields 27 countries, and 48,671 participants. -->

# Assumption checks and and contingencies

## Influential observations

-   **Check:** cook's D values exceeding the threshold 4/n; where n = \# of clusters.
-   **Treatment:** winzorize variables that demonstrate exhibit sufficient influence on model
-   **Robustness check:**

a.  Retain the level-1 cases of extreme values, add a dummy variable at level-2 to control for their unit, rerun analysis (Van de Meer et al, 2010). Document whether any coefficients change.

b.  Run analyses excluding cases that exceed the threshold 4/n; where n = \# of clusters. Following, evaluate cook's D values on this reduced dataset.

c.  Eliminate any cases that exceed a cook's d of .5, and conduct a third analysis.

*Then document whether any coefficients have gained/lost significance*

## Linearity

-   **Check:** Scatterplots for nonlinear relationships
-   **Treatment:** If robust nonlinear relationship detected, add polynomials until adequate fit to linear function is obtained

Nonlinearity does not seem to be a major issue in the data. There may be some pattern of as much as a third-order polynomial in the effects of gini on victimization, (second-order for GDP).

Especially with a small sample at level-2, adding polynomials seems more likely to risk overfitting the data. I would only assess the fit of a polynomial model if I could then test it on another dataset, for cross-validation.

## Normality in residuals

-   **Check**: QQplots (The Normal Probability Plot method.) for whether lie on normal distribution

**NO treatment:** Although there are many possible transformations possible for this kind of data (square root, rankit/INT, log(x+1), boxcox(x+1)), nonnormal data, by itself, is not expected to adversely impact the proposed analysis. Lumley, Diehr, Emerson, & Chen (2002) provided simulation evidence that linear regressions conducted on large samples are robust to departures from normality. With at least 500 observations, they found that linear regression can be conducted with negligible impact on Type I errors.

## Heteroscedasticity (Homogeneity of Variance)

-   **Check**: Plot residuals vs predicted values, for changes in residual variance across levels of predicted values

-   **Treatment:** Transformation of DV (e.g., box-cox, square root, log, rankit). Beyond this, the model already has robust standard errors

> There is a two-parameter version of the Box-Cox transformation that allows a shift before transformation:\The usual Box-Cox transformation sets λ2=0. One common choice with the two-parameter version is λ1=0 and λ2=1 which has the neat property of mapping zero to zero. There is even an R function for this: log1p(). More generally, both parameters can be estimated. In R, the boxcox.fit() function in package geoR will fit the parameters.

<!-- Inverse hyperbolic sine (IHS) transformation, mixture models (<https://robjhyndman.com/hyndsight/transformations/>) Other options: -->

> For a heteroskedasticity robust F test we perform a Wald test using the waldtest function, which is also contained in the lmtest package. It can be used in a similar way as the anova function, i.e., it uses the output of the restricted and unrestricted model and the robust variance-covariance matrix as argument vcov. Based on the variance-covariance matrix of the unrestriced model we, again, calculate White standard errors.

Wald test: a way to find out if explanatory variables in a model are significant.

If the Wald test shows that the parameters for certain explanatory variables are zero, you can remove the variables from the model

Weighted distance between the unrestricted estimate and its hypothesized value under the null hypothesis, where the weight is the precision of the estimate

<!-- >knief2021  Most elegantly,heteroscedasticity can be modeled directly, for instance by using the "weights" argument in lme (see Pinheiro & Bates, 2000, p. 214), which also enables us to test directly whether allowing for heteroscedasticity increases the fit of the model significantly. Similarly, heteroscedasticity-consistent standard errors could be estimated (Hayes & Cai, 2007). For more advice on handling heteroscedasticity, see McGuinness (2002). -->

## Multicolinnearity

-   **Check**: VIF/tolerances
-   **Fix** remove values \>= 5

> we did not cover collinearity between predictors or the distribution of random effects, but others have dealt with these aspects before (Freckleton, 2011; Schielzeth et al., 2020).

```{r victimization transformation, warning=F, message=FALSE, echo=FALSE}
# Square root method
iv_2005_mod$sqrt_victimization <- sqrt(iv_2005_mod$num_victim_5yr)
  # normality_stats(iv_2005_mod$sqrt_victimization)

# Cube root method
iv_2005_mod$cubrt_victimization <- '^'(iv_2005_mod$num_victim_5yr,1/3) # cube root transformation
  #normality_stats(iv_2005_mod$cubrt_victimization)

# rankit method
iv_2005_mod$rankit_victimization <- RNOmni::RankNorm(iv_2005_mod$num_victim_5yr) # rank-based inverse normal transformation (approximately normalize most distribtutional shapes, and which effectively minimizes type I errors and maximizes statistical power; Bishara & Hittner, 2012; Puth et al., 2014
  #normality_stats(iv_2005_mod$rankit_victimization)

#ggplot(iv_2005_mod, aes(x = rankit_victimization))  +  geom_histogram(binwidth= 1, alpha=.7, fill="#40B0A6", colour='grey') + geom_density(adjust=6, aes(y=..count..)) + theme_minimal()

# Ordinal method
iv_2005_mod$ordinal_victimization <- NA
iv_2005_mod$ordinal_victimization <- ifelse(between(iv_2005_mod$num_victim_5yr,0,1), 1, NA)
iv_2005_mod$ordinal_victimization[iv_2005_mod$num_victim_5yr == 0] <- 0 
iv_2005_mod$ordinal_victimization[iv_2005_mod$num_victim_5yr > 1] <- 2

# Log method
iv_2005_mod$log_victimization <- log10(iv_2005_mod$num_victim_5yr+1)
  #normality_stats(iv_2005_mod$log_victimization)


```

```{r sqrt security, warning=F, message=FALSE, echo=FALSE}
# Square root method
iv_2005_mod$sqrt_security <- sqrt(iv_2005_mod$total_security) # square root transformation seems to provide something closer, so just use that?

  #hist_plot(iv_2005_mod, sqrt_security, "Histogram of Total Security (Square root)")
  #normality_stats(iv_2005_mod$sqrt_security)


# Ordinal security
iv_2005_mod$ordinal_security <- NA

iv_2005_mod$ordinal_security <- ifelse(between(iv_2005_mod$total_security,0,1), 1, NA)
iv_2005_mod$ordinal_security[iv_2005_mod$total_security == 0] <- 0 
iv_2005_mod$ordinal_security[iv_2005_mod$total_security > 1] <- 2
  # hist_plot(iv_2005_mod, ordinal_security, "Histogram of Ordinal Security")
  # normality_stats(iv_2005_mod$ordinal_security)

# log+1 method
iv_2005_mod$log_security <- log10(iv_2005_mod$total_security+1)
  # hist_plot(iv_2005_mod, log_security, "Histogram of Logged Security")
  # normality_stats(iv_2005_mod$log_security)


# inverse method
iv_2005_mod$inv_security <- 1/(iv_2005_mod$total_security+1)
  # hist_plot(iv_2005_mod, inv_security, "Histogram of inverted Security")

# Box Cox Method
security_boxcox<- geoR::boxcoxfit(iv_2005_mod$total_security, lambda=0, lambda2 = 1) 
  # security_boxcox <- MASS::boxcox(iv_2005_mod$total_security)
```

# Exploration

```{r total security, warning=F, message=FALSE, echo=FALSE, fig.show="hold", out.width="50%"}
hist_plot(iv_2005_mod, total_security, "Histogram of Total Security")
hist_plot(iv_2005_mod, num_victim_5yr, "Histogram of victimizations over past 5 years")

```

```{r security summary}
summary(iv_2005_mod$total_security)

normality_stats(iv_2005_mod$total_security)
```

## On the distribution

The population distribution for our dependent variables is not known in advance. All we can say is that we know it is a count variable. This uncertainty opens up the possibility of a model selection bias

At first glance, victimization looks like a poisson process, but we have limited reason to believe that our outcome variables (e.g., security, number of victimizations) follow a strictly poisson process. Namely, violating the assumption that the occurence of one event does not affect occurrence of a subsequent event. I would guess that purchasing security or being victimized by a crime has *some* effect on later occurrences in either direction (e.g., having less money from the prior security purchase).

One note is that victimizations seem to have inflated zeros - more indicative of negative binomial. Another is that both variables have larger variances than means. A question though - is the independence supposed to be observed within observations or between observations?

All told, let's remember that the assumptions of normality apply to the distribution of residuals, so can only be interpreted in the model. Important to keep skewness of the DV on our radar though.

This summing procedure gives us a max score of `r max(iv_2005_mod$total_security)` on security consumption, with substantial positive skew

Starting with scatterplots. Nation Values with a cook's distance of 4 times the mean cook's distance values (for bivariate relationship) are flagged.

## Influential observations

```{r influence screen, warning=F, message=FALSE, echo=FALSE}
gd <- iv_2005_mod %>% 
        filter(!is.na(num_victim_5yr)) %>%
        group_by(country) %>% 
        summarise(gdppc_2004_6 = mean(gdppc_2004_6),
                  gdppc_2004_6_winz = mean(gdppc_2004_6_winz),
                  gdppc_2004_6_cent = mean(gdppc_2004_6_cent),
                  num_victim_5yr  = mean(num_victim_5yr),
                  num_victim_5yr_winz = mean(num_victim_5yr_winz),
                  gini_2004_6  = mean(av_gini),
                  gini_winz = mean(gini_2004_6_winz)
                  )

# gd <- iv_2005_mod %>% 
#         filter(!is.na(num_victim_5yr)) %>%
#         group_by(country) %>% 
#         summarise(gdppc_2004_6 = mean(gdppc_2004_6),
#                   gdppc_2004_6_winz = mean(gdppc_2004_6_winz),
#                   num_victim_5yr  = mean(num_victim_5yr),
#                   num_victim_5yr_winz = mean(num_victim_5yr_winz),
#                   gini_2004_6  = mean(av_gini),
#                   gini_winz = mean(gini_2004_6_winz)
#                   )

gd$country <- as.character(gd$country)

# gd$country <- as.factor(gd$country)

victim_age <- ggplot(iv_2005_mod, aes(x = age_cent, y = num_victim_5yr)) +
    geom_point(alpha = .02, position = "jitter", color = "#40B0A6") + geom_smooth(alpha = .25, color = "red", span = 1.25) + geom_smooth(method = "lm", alpha = .25) + theme_minimal()+ ggtitle("Age & victimization")


gini_gdp_full <- gd %>% 
  mutate(cooks = cooks.distance(lm(gini_2004_6 ~ gdppc_2004_6)),
         outlier_country = ifelse(cooks > 4*mean(cooks), country, NA)) %>%
  ggplot(aes(x = gini_2004_6, y = gdppc_2004_6, label = outlier_country)) +
  geom_point(position = "jitter") + geom_smooth(alpha = .25, color = "red", span = 1.25) + geom_smooth(method = "lm", alpha = .25) + ggtitle("Gini & GDP - Full") + theme_minimal() + coord_cartesian(xlim = c(20, 65), ylim = c(-10000, 85000)) + ggrepel::geom_label_repel()


# victim GINI plot with outliers
victim_gini_full <- gd %>% 
  mutate(cooks = cooks.distance(lm(num_victim_5yr ~ gini_2004_6)),
         outlier_country = ifelse(cooks > 4*mean(cooks), country, NA)) %>%
  ggplot(aes(x = gini_2004_6, y = num_victim_5yr, label = outlier_country)) +
  geom_point(position = "jitter") + geom_smooth(alpha = .25, color = "red", span = 1.5) + geom_smooth(method = "lm", alpha = .25) + ggtitle("Victimization & Gini - Full") + theme_minimal() + coord_cartesian(xlim = c(20, 65), ylim = c(.25, 1.125)) + ggrepel::geom_label_repel()


# victim GDP plot with outliers
victim_gdp_full <- gd %>% 
  mutate(cooks = cooks.distance(lm(num_victim_5yr ~ gdppc_2004_6)),
         outlier_country = ifelse(cooks > 4*mean(cooks), country, NA)) %>%
  ggplot(aes(x = gdppc_2004_6, y = num_victim_5yr, label = outlier_country)) +
  geom_point(position = "jitter") + geom_smooth(alpha = .25, color = "red", span = 1.25) + geom_smooth(method = "lm", alpha = .25) + ggtitle("Victimization & GDP - Full") + theme_minimal() + coord_cartesian(xlim = c(0, 85000), ylim = c(.25, 1.125)) + ggrepel::geom_label_repel(label.size = 0.02)

gridExtra::grid.arrange(victim_age, victim_gini_full,victim_gdp_full, gini_gdp_full, nrow = 2, ncol=2)
```

# Assuming a normal distribution

The case for using a normal distribution:

Initially, a poisson process seems to better describe the distribution of this study's dependent variable. However, the variables *num_victim_5yr* and *security_total* each likely violate the assumption of event independence, where one event does not affect the likelihood of a subsequent event. For instance, in the case of security consumption, the psychological and material impacts of buying a security product (e.g., feelings of safety, reduced budget), can plausibly impact a consumers' decision to purchase further security goods.

@knief2021 found a Gaussian error distribution to be far more robust to violations of its assumptions than Poisson and Binomial distributions. Given the potential for heavy bias in poisson and negative binomial models, a gaussian error structure's comparative robustness appears to make a (violated) assumption of normality be the safer choice compared to a possibly misattributed poisson distribution.

> We have shown that Poisson models yielded heavily biased type I error rates (at α = 0.05) in either direction ranging from 0 to as high as 0.55 when their distribution assumption is violated (Fig. 3 right column, Fig. S7).

@knief2021 also concluded that for anything other than very small sample sizes:

> "p-values from Gaussian models are highly robust to even extreme violation of the normality assumption and can be trusted, except when involving X and Y distributions with extreme outliers (p. ??). Likewise, "for N = 1000, power was essentially unaffected by the distribution of Y and X."

For our purposes, it is important to note that we are dealing with a small sample size at the cluster/nation level.

## Model-based exploration

Assuming a normal distribution, there are obviously some heavy tails in this data.

```{r estimation preview2, warning=T, message=FALSE}
# Fixed effect variables in model
summary(iv_2005_mod[,c("num_victim_5yr", "age_cent", "employed", "male")])

summary(gd[,c("gini_2004_6", "gdppc_2004_6_cent", "gdppc_2004_6")])

m1_null <- lme4::lmer(num_victim_5yr ~ (1 | country), data = iv_2005_mod, REML=FALSE)

# Estimate model
m1_sample <- lme4::lmer(num_victim_5yr ~ gini_2004_6_cent + gdppc_2004_6_scale + 
                     age_cent + employed + male + police_effective + income_quartile + (1 | country), data = iv_2005_mod, REML=FALSE)

#row-maximizing model
# m1_sample <- lme4::lmer(num_victim_5yr ~ gini_2004_6_cent + gdppc_2004_6_scale +
#                     age_cent + employed + male + police_effective + income_quartile + (1 | country), data = iv_2005_mod, REML=FALSE)

# call basic unweighted model
summary(m1_sample)

# estimate weighted model - fails to converge (even with all numeric variables scaled)
m1_weight <- lme4::lmer(num_victim_5yr ~ gini_2004_6_cent + gdppc_2004_6_scale + age_cent + employed +   male + (1 | country),data = iv_2005_mod, REML=FALSE, weights = individual_weight)
```

Further seen in the normality statistics for the residuals - high skewness and kurtosis

```{r model skewness kurtosis,  warning=F, message=FALSE}
moments::skewness(resid(m1_sample))
moments::kurtosis(resid(m1_sample))
```

Indeed, this model's residuals are definitely not normally-distributed, with a skewness of `r round(moments::skewness(resid(m1_sample)),2)`, and a kurtosis of `r round(moments::kurtosis(resid(m1_sample)),2)`. However, this is not yet the time to examine the residual plots - we need to explore and treat any potential influential observations that might be exacerbating these violations of normality.

> Note that this is based on simple aggregates. It is not based on empirical Bayesian estimates Doesn't take sampling variation due to sampling of into account Therefore a rough guide, but only rough

### Cook's distance ( R package influence.ME )

**Other influence stats**

DFBeta values: difference between estimate including and deleting outlier

DFFit: difference between adjusted predicted value and original value

```{r cooksd model, warning=F, message=FALSE, fig.show="hold", out.width="50%"}
# influential cases (Cook's Distance. Any values over 1 are likely to be significant outliers)
cooksD <- cooks.distance(m1_sample)
summary(cooksD)
```

```{r cooksd lv2, warning=F, message=FALSE, echo=FALSE, fig.show="hold", out.width="50%"}
# look for influential observations in nation-level
plot(cooksD, main="Model-wide Cook's D * BEWARE Y AXIS", ylim=c(0,.01))
abline(h = 4/nrow(iv_2005_mod), lty = 2, col = "steelblue") # add cutoff line
abline(h = 4*mean(cooksD, na.rm=T), col="red") 


victim_nation_cook <- cooks.distance(lm(num_victim_5yr ~ gini_2004_6 + gdppc_2004_6, gd))

plot(victim_nation_cook, main="Cook's D, Victimization ~ Gini + GDP", ylim=c(0,1))
abline(h = 4/nrow(gd), lty = 2, col = "steelblue") # add cutoff line
abline(h = 4*mean(victim_nation_cook, na.rm=T), col="red") 
text(x=1:length(victim_nation_cook)+1, y=victim_nation_cook, labels=ifelse(victim_nation_cook>4*mean(victim_nation_cook, na.rm=T), gd$country,""), col="red") 

```

A model-wide Cook's D shows that any given observation has a small influence on the entire model - to be expected with such a large sample. This is why it's important to break the analysis of influential variables into multiple levels

We can see that level-2 analysis yields much larger Cook's D values. The cooks distance values are all well under 1. Importantly, this is the same for the nation-level variables; they have a smaller sample size - and are thus the more susceptible to influential observations.

**However, there are a few observations at nation-level that exceed the 4/n threshold, and some that exceed 0.5. Generally, there are changes in the slope, but ultimately the direction doesn't change**

## Handling influential observations - Winzorization

Going on with citing @knief2021:

> "Importantly, the robustness of regression methods to deviations from normality of the regression errors e does not only depend on sample size, but also on the distribution of the predictor X (Box & Watson, 1962; Mardia, 1971). Specifically, when the predictor variable X contains a single outlier, then it is possible that the case coincides with an outlier in Y, creating an extreme observation with high leverage on the regression line. This is the only case where statistical significance gets seriously misestimated based on the assumption of Gaussian errors in Y which is violated by the outlier in Y. This problem has been widely recognized (Ali & Sharma, 1996; Box&Watson, 1962; Miller, 1986; Osborne &Waters, 2002; Ramsey & Schafer, 2013; Zuur et al., 2010) leading to the conclusion that Gaussian models are robust as long as there are Trimmed values \> 4\*mean(cook) that occur in X and Y simultaneously."

Since these influential observations are not a mistake - but rather truly extreme data, we will not delete the data, but instead winzorize these extreme values.

```{r winzorized descriptives, warning=F, message=FALSE, echo=FALSE, fig.show="hold", out.width="50%"}
iv_2005_mod[,c("num_victim_5yr", "num_victim_5yr_winz")] %>%
  summary()

gd[,c("gdppc_2004_6", "gdppc_2004_6_winz", "gini_2004_6", "gini_winz")] %>%
  summary()
```

Dramatic changes to the max values, less-so for the mean values (with the exception of number of victimizations)

```{r winzorize histograms, warning=F, message=FALSE, echo=FALSE}

gridExtra::grid.arrange(


hist_plot(iv_2005_mod,num_victim_5yr,"Regular number of victimizations"),
hist_plot(iv_2005_mod,num_victim_5yr_winz,"Winzorized number of victimizations"),


hist_plot(gd,gdppc_2004_6,"Regular GDP"),
hist_plot(gd,gdppc_2004_6_winz,"Winzorized GDP"),

hist_plot(gd,gini_2004_6,"Regular Gini"),
hist_plot(gd,gini_winz,"Winzorized Gini"),

nrow = 3, ncol=2)

```

### Winzorized plots

```{r winz scatter, warning=F, message=FALSE, echo=FALSE, fig.show="hold", out.width="50%"}
gini_gdp_winz <- gd %>% 
  mutate(cooks = cooks.distance(lm( gdppc_2004_6_winz ~ gini_winz)),
         outlier_country = ifelse(cooks > 4*mean(cooks), country, NA)) %>%
  ggplot(aes(x = gini_winz, y = gdppc_2004_6_winz, label = outlier_country)) +
  geom_point(position = "jitter") + geom_smooth(alpha = .25, color = "red", span = 1.6) + geom_smooth(method = "lm", alpha = .25) + ggtitle("Gini & GDP - Winzorized") + theme_minimal() + coord_cartesian(xlim = c(20, 65), ylim = c(-10000, 85000)) + ggrepel::geom_label_repel()

# victim GINI plot, winzorized
victim_gini_winz <- gd %>% 
  mutate(cooks = cooks.distance(lm(num_victim_5yr_winz ~ gini_winz)),
         outlier_country = ifelse(cooks > 4*mean(cooks), country, NA)) %>%
  ggplot(aes(x = gini_winz, y = num_victim_5yr_winz, label = outlier_country)) +
  geom_point(position = "jitter") + geom_smooth(alpha = .25, color = "red", span = 1.6) + geom_smooth(method = "lm", alpha = .25) + ggtitle("Victimization & Gini - Winzorized") + theme_minimal() + coord_cartesian(xlim = c(20, 65), ylim = c(.25, 1.125)) + ggrepel::geom_label_repel()

# victim GDP plot, winzorized
victim_gdp_winz <- gd %>% 
  mutate(cooks = cooks.distance(lm(num_victim_5yr_winz ~ gdppc_2004_6_winz)),
         outlier_country = ifelse(cooks > 4*mean(cooks), country, NA)) %>%
  ggplot(aes(x = gdppc_2004_6_winz, y = num_victim_5yr_winz, label = outlier_country)) +
  geom_point(position = "jitter") + geom_smooth(alpha = .25, color = "red", span = 1.6) + geom_smooth(method = "lm", alpha = .25) + ggtitle("Victimization & GDP - Winzorized") + theme_minimal() + coord_cartesian(xlim = c(0, 85000), ylim = c(.25, 1.125)) + ggrepel::geom_label_repel(label.size = 0.02)



victim_gini_full
victim_gini_winz
victim_gdp_full
victim_gdp_winz
# gini_gdp_full
# gini_gdp_winz
```

```{r sqrt winz, echo = FALSE, warning=FALSE}
iv_2005_mod <- iv_2005_mod %>%
  filter(!is.na(num_victim_5yr)) %>%
  mutate(num_victim_5yr_winz_sqrt = sqrt(num_victim_5yr_winz),
          gdppc_2004_6_winz_sqrt = sqrt(gdppc_2004_6_winz),
          gini_2004_6_winz_sqrt = sqrt(gini_2004_6_winz),
         num_victim_5yr_winz_rankit = RNOmni::RankNorm(num_victim_5yr+1)
         )

m1_winz_sqrt <- lme4::lmer(num_victim_5yr_winz_sqrt ~ gdppc_2004_6_winz_sqrt + gini_2004_6_winz_sqrt +
                     age_cent + employed + male + police_effective + income_quartile + (1 | country),data = iv_2005_mod, REML=FALSE)
```

```{r winzorize model, message=F, warning=FALSE}
m1_winz <- lme4::lmer(num_victim_5yr_winz ~ gdppc_2004_6_wc + gini_2004_6_winz +
                     age_cent + employed + male + police_effective + income_quartile + (1 | country),data = iv_2005_mod, REML=FALSE)
```

```{r model winz skewness kurtosis,  warning=F, message=FALSE}
moments::skewness(resid(m1_winz))
moments::kurtosis(resid(m1_winz))
```

Winzorizing reduces non-normality, from a skewness of `r round(moments::skewness(resid(m1_sample)),2)` to skewness of *`r round(moments::skewness(resid(m1_winz)),2)`*, and from a kurtosis of `r round(moments::kurtosis(resid(m1_sample)),2)` to *`r round(moments::kurtosis(resid(m1_winz)),2)`*

QQplots likewise suggest the reduction (but not resolution) of nonnormal error distributions

```{r Normality, warning=F, message=FALSE, echo=FALSE, fig.show="hold", out.width="50%"}
qqnorm(resid(m1_sample))
qqline(resid(m1_sample), col = "darkgreen")

plot(fitted(m1_sample),resid(m1_sample), main = "Normal resid ~ fitted")


qqnorm(resid(m1_winz), main = "Winzorized gini + victim - QQ plot")
qqline(resid(m1_winz), col = "darkgreen")

plot(fitted(m1_winz),resid(m1_winz), main = "Winzorized resid ~ fitted")


# qqnorm(resid(m1_winz_sqrt), main = "sqrt winzorized gini + victim - QQ plot")
# qqline(resid(m1_winz_sqrt), col = "darkgreen")

```

Winzorizing definitely seems to help the normality of the model. Again, it does not remedy normality by any stretch; there are still some very heavy tails

Likewise, there is some imbalance in the resid\~fitted plots, with more positive residuals accompanying smaller fitted values.

# Poisson distribution

Poisson is the go-to distribution for handling count data, which tends to exhibit a positive skew, and could provide an alternate way to model our data.

<!-- poisson assumptions \* rate at which events occur is constant \* occurence of one event does not affect occurence of a subsequent event -->

<!-- Probability Mass Function (PMF) - how likely a given value is -->

<!-- cumulative distribution function - all of the likelihoods of values up to and including the designated value -->

```{r pois dis, message=FALSE}
library('fitdistrplus')
plot(fitdist(iv_2005_mod$total_security,"pois"))
plot(fitdist(iv_2005_mod$num_victim_5yr,"pois"))


# ggplot(data = iv_2005_mod,
#        mapping = aes(sample = total_security)) + 
#   stat_qq(distribution = stats::qpois,
#           dparams = list(lambda = mean(iv_2005_mod$total_security))) + 
#   geom_step(data = data.frame(x = 0:10,
#                               total_security = 0:10),
#             mapping = aes(x = x,
#                           y = total_security),
#             colour = "red",
#             alpha = 0.5) 

# print("Security mean is")
mean(iv_2005_mod$total_security)
# print("Security variance is")
var(iv_2005_mod$total_security)

# print("Victimization mean is")
mean(iv_2005_mod$num_victim_5yr)
# print("Victimization variance is")
var(iv_2005_mod$num_victim_5yr)
```

Mean and variance values are slightly overdispersed (larger variances than means) - How close do they need to be to argue for poisson?

Specifying the poisson model:

```{r poisson model, message=FALSE, fig.show="hold", out.width="50%"}
m_pois <- glmer(num_victim_5yr ~ gdppc_2004_6_scale + gini_2004_6_cent + age_cent + employed + male + police_effective + income_quartile + (1 | country), family = poisson, data = iv_2005_mod)
```

## Poisson assumptions and contingencies

The traditional procedure for testing binomial assumptions is conducted in seven steps:

1\. Conduct the D&L score test for overdispersion (H0: Poisson vs. H1: NB).

2\. If the D&L score test fails to reject the null, conduct a Vuong test for zero-inflation (H0: Poisson vs. H1: ZIP). *Otherwise, proceed to Step 5*.

3\. If the Vuong test for zero-inflation fails to reject the null, **fit a Poisson GLM** and calculate the p-value (H0 : βX = 0 vs. H1 : βX ≠ 0). *Otherwise, proceed to Step 4.*

4\. If the Vuong test for zero-inflation rejects the null, **fit the ZIP model** and calculate the p-value (H0 : βX = γX = 0).

5\. If the D&L score test rejects the null, conduct the Vuong test for zero-inflation (H0: NB vs. H1: ZINB).

6\. If the Vuong test for zero-inflation fails to reject the null, **fit the NB model** and calculate the p-value (H0 : βX = 0). *Otherwise, proceed to Step 7.*

7\. If the Vuong test for zero-inflation rejects the null, **fit the ZINB regression model** and calculate the p-value (H0 : βX = γX = 0).

Following a simulation analysis of this seven-step testing procedure @campbell2021 discusses the consequences of testing the assumptions of a poisson distribution:

> if one does not have sufficient power to confidently test for overdispersion and zero-inflation, it may be best to simply use a model that can accommodate for these possibilities (e.g. use a robust model) instead of going through a model selection procedure that might inflate the type 1 error.

> However, when the distributional assumptions of a Poisson GLM do hold, Tsou (2006) acknowledge that the 'robust approach might not be as efficient'.

This loss of efficiency reduces statistical power, so researchers may seek other methods to correct for model selection bias

> Our simulation study suggests that, if sample sizes are sufficiently large, there is little need to worry about model selection bias following a series of sequential score tests. However, when sample sizes are small, our simulation study demonstrated that model selection bias can lead to potentially substantial type 1 error inflation

The assumptions for poisson (and negative binomial) models will be tested using the r package **DHARMa: residual diagnostics for hierarchical (multi-level/mixed) regression models**

> The 'DHARMa' package uses a simulation-based approach to create readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed models.

<!-- Currently supported are linear and generalized linear (mixed) models from ‘lme4’ (classes ‘lmerMod’, ‘glmerMod’), ‘glmmTMB’, ‘GLMMadaptive’ and ‘spaMM’, generalized additive models (‘gam’ from ‘mgcv’), ‘glm’ (including ‘negbin’ from ‘MASS’, but excluding quasi-distributions) and ‘lm’ model classes -->

> To interpret the residuals, remember that a scaled residual value of 0.5 means that half of the simulated data are higher than the observed value, and half of them lower. A value of 0.99 would mean that nearly all simulated data are lower than the observed value.

```{r dharma}
library(DHARMa) #  “Diagnostics for HierArchical Regression Models”
simulationOutput <- simulateResiduals(fittedModel = m_pois, plot = F)
```

### Overdispersion

As said above, overdispersion describes excess variance, given the mean.

\- **Check:** DHARMA:: testDispersion() - **Treatment:** negative binomial model - **Robustness check:**

```{r dharma dispersion}
testDispersion(simulationOutput)

# another package, blemco

blmeco::dispersion_glmer(m_pois)  # chec for dispersion, cutoff 1.4 https://stackoverflow.com/questions/22842017/model-checking-and-test-of-overdispersion-for-glmer
# # cutoff 1.1 https://stats.stackexchange.com/questions/230721/how-to-check-overdispersion-of-binomial-glmms-lme4-package
```

### Zero-inflation

Zero-inflation describes the extent to which more zeros are present in the data than what the distribution assumes

-   **Check:** DHARMA:: testZeroInflation()
-   **Treatment:** zero-inflated model

```{r dharma zero inflation}
testZeroInflation(simulationOutput)
```

Simulation outliers (data points that are outside the range of simulated values) are highlighted as red stars. To provide a visual aid in detecting deviations from uniformity in y-direction, the plot function calculates an (optional default) quantile regression, which compares the empirical 0.25, 0.5 and 0.75 quantiles in y direction (red solid lines) with the theoretical 0.25, 0.5 and 0.75 quantiles (dashed black line), and provides a p-value for the deviation from the expected quantile.

```{r dharma outliers}
testOutliers(simulationOutput)
```

By default, plotResiduals plots against predicted values. However, you can also use it to plot residuals against a specific other predictors (highly recommend).

```{r dharma plot against}
testQuantiles(simulationOutput)

plotResiduals(simulationOutput, form = iv_2005_mod$gini_2004_6_cent)
```

```{r poisson qq, echo = FALSE}
# qqnorm(resid(m_pois), main = "Poisson - QQ plot")
# qqline(resid(m_pois), col = "darkgreen")
# plot(fitted(m_pois),resid(m_pois), main = "Poisson resid ~ fitted")

# Likewise qq plot indicates the bottom quantiles deviate from the normality line. Not sure whether it's anticipated, but some indication of heteroscedasticiy in the poisson model, with variance decreasing with larger fitted values
```

```{r dharma plots}
plot(simulationOutput)
```

```{r poisson overdispersion, message=FALSE}
blmeco::dispersion_glmer(m_pois)  # chec for dispersion, cutoff 1.4 https://stackoverflow.com/questions/22842017/model-checking-and-test-of-overdispersion-for-glmer
# # cutoff 1.1 https://stats.stackexchange.com/questions/230721/how-to-check-overdispersion-of-binomial-glmms-lme4-package
# 
# # zero inflation test https://stats.stackexchange.com/questions/118322/how-to-test-for-zero-inflation-in-a-dataset
# vcdExtra::zero.test(iv_2005_mod$total_security)
```

## Other packages to run modified glmm

<!-- https://stats.stackexchange.com/questions/474228/zero-inflated-generalized-poisson-mixed-effect-model-with-glmmtmb-still-zero-inf  -->

glmmTMB package with a Zero-inflated generalized Poisson

<!-- https://drizopoulos.github.io/GLMMadaptive/ -->

GLMMadaptive: fits mixed effects models for grouped/clustered outcome variables

**Vuong test**: a test of distinghuishability and fit for two models compares the zero-inflated model with an ordinary Poisson regression model

```{r vuong}
# https://stackoverflow.com/questions/51016328/mixed-effects-model-with-zero-inflated-data-error-message-using-zeroinfl-fro 
# m_nbinom <- glmmTMB::glmmTMB(num_victim_5yr ~ gdppc_2004_6_scale  + av_gini + age_cent + employed + male + police_effective + income_quartile + (1 | country),zi = ~ gdppc_2004_6_scale  + av_gini + age_cent + employed + male, data = iv_2005_mod, family = poisson)
# 
# summary(m_nbinom)

# If you set zi ~ 1 then the ZIM is assumed to be independent of any predictors. 

# Interpreting zero-inflation coefficients: every unit change in predictor increases/decreases the log odds of the being in the structural zero group (those who cannot have cancer) 

# mnull <- update(m_nbinom)
# 
# pchisq(2 * (logLik(m_nbinom) - logLik(mnull)), df = 3, lower.tail = FALSE)
# # 
# p1 <- glm(count ~ child + camper, family = poisson, data = zinb)
# 
# pscl::vuong(m1,m_pois)
```

```{r nbinom, echo=FALSE}

# m_bino <- glmer.nb(num_victim_5yr ~ gdppc_2004_6_scale + gini_2004_6_cent + age_cent + employed + male + police_effective + income_quartile + (1 | country),data = iv_2005_mod)
# 
# bino_sim <- simulateResiduals(fittedModel = m_bino, plot = F)

# testDispersion(m_bino)
# testDispersion(bino_sim)
# testZeroInflation(bino_sim)

# qqnorm(resid(m_bino), main = "negative binomial - QQ plot")
# qqline(resid(m_bino), col = "darkgreen")
# plot(fitted(m_bino),resid(m_bino), main = "negative binomial resid ~ fitted")


#compares Zero-inflated Poisson regression
# pscl::vuong(poisson,zero inflat pois)

```

```{r other distributions, warning=F, message=FALSE, echo=FALSE, results='hide', fig.show="hold", out.width="50%"}
# https://www.juliapilowsky.com/2018/10/19/a-practical-guide-to-mixed-models-in-r/

# # unexpected missingness exclusion
# summary(!is.na(iv_2005_mod[["num_victim_5yr"]]))
# which(is.na(iv_2005_mod[["num_victim_5yr"]]))
# 
# iv_2005_mod$num_victim_5yr_winz_1 <- iv_2005_mod$num_victim_5yr_winz + 1
# 
# norm <- MASS::fitdistr(iv_2005_mod$num_victim_5yr_winz_1, "normal")
# 
# # qqp(iv_2005_mod$num_victim_5yr, "norm", main = "Normal distribution")
# 
# qqp(iv_2005_mod$num_victim_5yr_winz_1, "norm", main = "Normal distribution")
# 
# 
# qqp(sqrt(iv_2005_mod$num_victim_5yr_winz), "norm", main = "Normal distribution, square root")
# # qqp(sqrt(iv_2005_mod$num_victim_5yr_winz), "norm", main = "winzorized and square root")
# 
# qqp(iv_2005_mod$num_victim_5yr_winz_1, "lnorm", main = "Logged normal distribution")
# # qqp(iv_2005_mod$num_victim_5yr_winz + 1, "lnorm", main = "Winzorized and Logged")
# 
# # negative binomial - fails to optimize with +1 transformation
# # nbinom <- MASS::fitdistr(iv_2005_mod$num_victim_5yr_1, "Negative Binomial")
# # qqp(iv_2005_mod$num_victim_5yr_1, "nbinom", main = "Negative binomial distribution", size = nbinom$estimate[[1]], mu = nbinom$estimate[[2]])
# 
# 
# #poisson distribution
# poisson <- MASS::fitdistr(iv_2005_mod$num_victim_5yr_winz_1, "Poisson")
# qqp(iv_2005_mod$num_victim_5yr_winz_1, "pois", main = "Poisson distribution", lambda = poisson$estimate)
# 
# 
# #poisson modeldistribution
# poisson <- MASS::fitdistr(iv_2005_mod$num_victim_5yr_winz_1, "Poisson")
# qqp(iv_2005_mod$num_victim_5yr_winz_1, "pois", main = "Poisson distribution", lambda = poisson$estimate)
# 

# qqp(iv_2005_mod$num_victim_5yr_winz+1, "pois", main = "Winzorized Poisson distribution", lambda = poisson$estimate)


# lattice::qqmath(m1_sample, id=0.05)
```

# Correlated random effects

@mcneish2017

pwcorr rint resids

-   graph of correlation between within-level residuals and random effects

twoway (scatter resids rint) (lfit resids rint)

from <https://notstatschat.rbind.io/2019/04/19/progress-on-linear-mixed-models-for-surveys/>

```{r heteroscedasticity, warning=F, message=FALSE, echo=FALSE, fig.show="hold", out.width="50%"}
# plot(m1_sample, resid(., type = "pearson") ~ fitted(.), abline = 0, main="Heteroscedasticity check - fitted values vs. residuals")
# 
# plot(m1_winz, resid(., type = "pearson") ~ fitted(.), abline = 0, main="Heteroscedasticity (Winzorized)")
```

The variance of residuals seems consistent across all levels - so no notable heteroscedasticity?

In particular, the residuals don't appear to be symmetrically distributed (tending to cluster towards the middle of the plot). For low fitted values, residuals seem to be skewed higher, leveling off as the fitted values get larger

> In R the function coeftest from the lmtest package can be used in combination with the function vcovHC from the sandwich package to obtain heteroskedasticity robust standard errors and their corresponding t values.

```{r VIF1, warning=F, message=FALSE}
performance::check_collinearity(m1_sample)

car::vif(m1_sample) # display VIF values
```

@mcneish2017

> [Design-based] methods estimate a general or generalized linear model and provide standard errors that are robust to misspecifications of the covariance matrix of the outcome variable. Common methods in this class include so-called heteroscedasticity-corrected covariance matrix estimators or sandwich estimators (Huber, 1967; White, 1980), and generalized estimating equations (GEEs; Liang and Zeger, 1986) DBMs are often employed when the marginal response is of interest rather than individual responses or how responses vary across clustering units.

## GEE: [Generalized linear models for dependent data](https://cehs-research.github.io/eBook_multilevel/gee-count-outcome-epilepsy.html)

@snijders2011**, on Generalized Estimating Equations (GEE) (p. 198)**

-   assumes linear or generalized linear model for the *expected values* of dependent variable in a multilevel data structure, conditional on the explanatory variables

-   No assumptions made with respect to the variances and correlations, except that these are independent between highest-level units

-   linear model parameters estimated through a working model

-   standard errors estimated through sandwich estimator

-   comparison between GEE and HLM discussed in Gardiner et al. 2009

-   LARGE SAMPLE METHOD - without large sample, need a tailored small-sample version with a differently defined sandwich estimators

## Sandwich estimators

**Snijders & Bosker, on sandwich estimators (p. 173)**

> sandwich estimators for standard errors, also called cluster-robust standard errors, make no assumptions about the distributional shape of the random coefficients. Verbeke and Lesaffre (1997) and Yan and Bentler (2002) proposed sandwich estimators to provide standard errors applicable for nonnormalily distributed random effects... However, sandwich estimators do require large enough numbers of units at the highest level; see Verbeke and Lesaffre 997), Maas and Hox (2004), and hthe further discussion in 12.2 \*

[<https://www.r-econometrics.com/methods/hcrobusterrors/>https://stackoverflow.com/questions/48479984/r-mixed-model-with-heteroscedastic-data-only-lm-function-works](https://www.r-econometrics.com/methods/hcrobusterrors/){.uri}

> The sandwich package is not limited to lm/glm only but it is in principle object-oriented, see vignette("sandwich-OOP", package = "sandwich") (also published as <doi:10.18637/jss.v016.i09>.

> <!--# There are suitable methods for a wide variety of packages/models but not for nlme or lme4. The reason is that it's not so obvious for which mixed-effects models the usual sandwich trick actually works. (Disclaimer: But I'm no expert in mixed-effects modeling.)  -->

> However, for lme4 there is a relatively new package called merDeriv (<https://CRAN.R-project.org/package=merDeriv>) that supplies estfun and bread methods so that sandwich covariances can be computed for lmer output etc. There is also a working paper associated with that package: <https://arxiv.org/abs/1612.04911>

Match Poisson Regresssion (GLM)

restricted maximum likelihood (REML)

-   REML, by accounting for the loss in degrees of freedom from estimating the fixed effects, provides an unbiased estimate of variance components, while ML estimators for variance components are biased under assumptions of normality, since they use estimated fixed effects rather than the true values.

# Other approaches

## Bootstrapping

[**lmeresampler**](http://aloy.github.io/lmeresampler/): provides an easy way to bootstrap nested linear-mixed effects models using either the parametric, residual, cases, CGR (semi-parametric), or random effects block (REB) bootstrap fit using either lme4 or nlme. The output from lmeresampler is an lmeresamp

**bootMer**

**Semi-parametric multilevel modeling** (Tihomir Asparouhov)

**Penalized quasilikelihood (PQL)**

flexible technique that can deal with non-normal data, unbalanced design, and crossed random effects. However, it produces biased estimates if your response variable fits a discrete count distribution, like Poisson or binomial, and the mean is less than 5 - or if your response variable is binary.

what if the mean of your response variable is less than 5, or you have a binary response variable, and you can't use PQL? Here you're going to have to make another decision, because there are two alternatives you can use: the **Laplace approximation** and **Markov chain Monte Carlo algorithms (MCMC)**. The Laplace approximation can handle up to 3 random effects. Any more than that, and you'll have to use MCMC, which is a Bayesian method that can be somewhat confusing.
<!--# https://www.juliapilowsky.com/2018/10/19/a-practical-guide-to-mixed-models-in-r/ -->

**laplace** looks like follows

    glmer(repeatgr ~ Minority + ses + ses * Minority + (1 | schoolNR),
        data = bdf, family = binomial(link = "logit"))

There is one more consideration, though, when using this method. It
becomes inaccurate when used on overdispersed data - that is, when the
combined residuals are much larger than the residual degrees of freedom.

**MCMCglmm**, which can not only handle many random effects, but provides confidence intervals for the random effects, MCM is a Bayesian statistical method. All models make assumptions about the distribution of the variance in your data, but in a Bayesian method these assumptions are explicit, and we need to specify these assumed distributions. In Bayesian statistics, we call these priors.

Just keep in mind that one **R structure** needs to be specified for each fixed effect and one **G structure** needs to be specified for each random effect. Also remember my caution about the lognormal distribution: these priors may not play nicely with data modeled with a log link, so do
some research on what priors to use for data on a log scale.

Looks like this:

    prior <- list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V = 1, n = 1),
        G2 = list(V = 1, n = 1), G3 = list(V = 1, n = 1), G4 = list(V = 1, n = 1),
        G5 = list(V = 1, n = 1)))
    set.seed(45)
    MCMC <- MCMCglmm(fixed = profit ~ 1, random = ~year + farmer + place + gen + district, data = farmers, family = "categorical", prior = prior, verbose = FALSE)

# Limitations

The most notable weakness is that this is data from WEIRD countries. Other, less WEIRD countries (e.g., phillipines, nigeria, india) are better represented throughout sweeps 2 to 4

Unaccounted third variables (e.g., corruption)

Small clusters, limited representativeness.

# References
